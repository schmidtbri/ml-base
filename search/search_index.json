{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the ML Base Package Documentation The ml_base package is useful for deploying machine learning models. Introduction The ml_base package defines a common set of base classes that are useful for working with machine learning model prediction code. The base classes define a set of interfaces that help to write ML code that is reusable and testable. The core of the ml_base package is the MLModel class which defines a simple interface for doing machine learning model prediction. The MLModel base class allows the developer of the model to return this information to the user of the model in a standardized way: Model Qualified Name, a unique identifier for the model Model Display Name, a friendly name for the model used in user interfaces Model Description, a description for the model Model Version, semantic version of the model codebase Model Input Schema, an object that describes the model's input data Model Output Schema, an object that describes the model's output schema The package also includes a ModelManager class that is able to instantiate and manage models that are created using the MLModel base class. The package also provides a way to create decorators that work with MLModel instances to enable more complex behavior for the decorated model. Examples for MLModel decorators can be found in the examples section of this site. FAQ Why bother with base classes and interfaces? Isn't it just extra work? Interface-driven software development can be very helpful when building complex software systems. By using the MLModel base class to deliver the prediction functionality, developing software that makes use of the machine learning model is greatly simplified, and the model is much more accessible and easier to use. Developing the prediction functionality of your ML model around the MLModel base class provides a simple \"meeting point\" between your model and anyone that wants to use it, the user doesn't need to worry about the implementation of the model and you don't need to worry about the use cases that your model will be used in. Why not just deliver a serialized model object to the software engineer? Having a class that wraps around your model object provides a great place to do things that make your model easier to use. For example: Deserialize model parameters from disk so that using the model is a easy as instantiating a class and calling predict() Validate inputs before sending them to the model. Modify predictions before sending them back to the calling code. Return metadata about your model. Convert model inputs from a developer-friendly data structure (dictionaries and lists) to a model-friendly data structure (dataframes). Convert model outputs from a dataframe to a dictionary or list. So what do I have to do to use the base classes? Create a wrapper class around your model that inherits from the MLModel base class and implement the required methods. You can follow the example implementation available in the documentation.","title":"Home"},{"location":"#welcome-to-the-ml-base-package-documentation","text":"The ml_base package is useful for deploying machine learning models.","title":"Welcome to the ML Base Package Documentation"},{"location":"#introduction","text":"The ml_base package defines a common set of base classes that are useful for working with machine learning model prediction code. The base classes define a set of interfaces that help to write ML code that is reusable and testable. The core of the ml_base package is the MLModel class which defines a simple interface for doing machine learning model prediction. The MLModel base class allows the developer of the model to return this information to the user of the model in a standardized way: Model Qualified Name, a unique identifier for the model Model Display Name, a friendly name for the model used in user interfaces Model Description, a description for the model Model Version, semantic version of the model codebase Model Input Schema, an object that describes the model's input data Model Output Schema, an object that describes the model's output schema The package also includes a ModelManager class that is able to instantiate and manage models that are created using the MLModel base class. The package also provides a way to create decorators that work with MLModel instances to enable more complex behavior for the decorated model. Examples for MLModel decorators can be found in the examples section of this site.","title":"Introduction"},{"location":"#faq","text":"","title":"FAQ"},{"location":"#why-bother-with-base-classes-and-interfaces-isnt-it-just-extra-work","text":"Interface-driven software development can be very helpful when building complex software systems. By using the MLModel base class to deliver the prediction functionality, developing software that makes use of the machine learning model is greatly simplified, and the model is much more accessible and easier to use. Developing the prediction functionality of your ML model around the MLModel base class provides a simple \"meeting point\" between your model and anyone that wants to use it, the user doesn't need to worry about the implementation of the model and you don't need to worry about the use cases that your model will be used in.","title":"Why bother with base classes and interfaces? Isn't it just extra work?"},{"location":"#why-not-just-deliver-a-serialized-model-object-to-the-software-engineer","text":"Having a class that wraps around your model object provides a great place to do things that make your model easier to use. For example: Deserialize model parameters from disk so that using the model is a easy as instantiating a class and calling predict() Validate inputs before sending them to the model. Modify predictions before sending them back to the calling code. Return metadata about your model. Convert model inputs from a developer-friendly data structure (dictionaries and lists) to a model-friendly data structure (dataframes). Convert model outputs from a dataframe to a dictionary or list.","title":"Why not just deliver a serialized model object to the software engineer?"},{"location":"#so-what-do-i-have-to-do-to-use-the-base-classes","text":"Create a wrapper class around your model that inherits from the MLModel base class and implement the required methods. You can follow the example implementation available in the documentation.","title":"So what do I have to do to use the base classes?"},{"location":"api/","text":"API documentation Base Classes Base class for building ML models that are easy to deploy and integrate. MLModel ( ABC ) Base class for ML model prediction code. Source code in ml_base/ml_model.py class MLModel ( ABC ): \"\"\"Base class for ML model prediction code.\"\"\" def __repr__ ( self ): \"\"\"Return a string representing the model object.\"\"\" return self . __class__ . __name__ @property @abstractmethod def display_name ( self ) -> str : \"\"\"Abstract property that returns a display name for the model. Returns: str: The display name of the model. !!! note This is a name for the model that looks good in user interfaces. \"\"\" raise NotImplementedError () # pragma: no cover @property @abstractmethod def qualified_name ( self ) -> str : \"\"\"Abstract property that returns the qualified name of the model. Returns: str: The qualified name of the model. !!! warning A qualified name is an unambiguous identifier for the model. \"\"\" raise NotImplementedError () # pragma: no cover @property @abstractmethod def description ( self ) -> str : \"\"\"Abstract property that returns a description of the model. Returns: str: The description of the model. \"\"\" raise NotImplementedError () # pragma: no cover @property @abstractmethod def version ( self ) -> str : \"\"\"Abstract property that returns the model's version as a string. Returns: str: The version of the model. \"\"\" raise NotImplementedError () # pragma: no cover @property @abstractmethod def input_schema ( self ): \"\"\"Property that returns the schema that is accepted by the predict() method. Returns: pydantic.BaseModel: The input schema of the model. !!! note This property must return a subtype of pydantic.BaseModel. \"\"\" raise NotImplementedError () # pragma: no cover @property @abstractmethod def output_schema ( self ): \"\"\"Property returns the schema that is returned by the predict() method. Returns: pydantic.BaseModel: The output schema of the model. !!! note This property must return a subtype of pydantic.BaseModel. \"\"\" raise NotImplementedError () # pragma: no cover @abstractmethod def __init__ ( self ) -> None : \"\"\"Create an MLModel instance by adding any deserialization and initialization code for the model.\"\"\" raise NotImplementedError () # pragma: no cover @abstractmethod def predict ( self , data ): \"\"\"Prediction with the model. Args: data: data used by the model for making a prediction Returns: object: can be any python type \"\"\" raise NotImplementedError () # pragma: no cover description : str property readonly Abstract property that returns a description of the model. Returns: Type Description str The description of the model. display_name : str property readonly Abstract property that returns a display name for the model. Returns: Type Description str The display name of the model. Note This is a name for the model that looks good in user interfaces. input_schema property readonly Property that returns the schema that is accepted by the predict() method. Returns: Type Description pydantic.BaseModel The input schema of the model. Note This property must return a subtype of pydantic.BaseModel. output_schema property readonly Property returns the schema that is returned by the predict() method. Returns: Type Description pydantic.BaseModel The output schema of the model. Note This property must return a subtype of pydantic.BaseModel. qualified_name : str property readonly Abstract property that returns the qualified name of the model. Returns: Type Description str The qualified name of the model. Warning A qualified name is an unambiguous identifier for the model. version : str property readonly Abstract property that returns the model's version as a string. Returns: Type Description str The version of the model. __init__ ( self ) special Create an MLModel instance by adding any deserialization and initialization code for the model. Source code in ml_base/ml_model.py @abstractmethod def __init__ ( self ) -> None : \"\"\"Create an MLModel instance by adding any deserialization and initialization code for the model.\"\"\" raise NotImplementedError () # pragma: no cover __repr__ ( self ) special Return a string representing the model object. Source code in ml_base/ml_model.py def __repr__ ( self ): \"\"\"Return a string representing the model object.\"\"\" return self . __class__ . __name__ predict ( self , data ) Prediction with the model. Parameters: Name Type Description Default data data used by the model for making a prediction required Returns: Type Description object can be any python type Source code in ml_base/ml_model.py @abstractmethod def predict ( self , data ): \"\"\"Prediction with the model. Args: data: data used by the model for making a prediction Returns: object: can be any python type \"\"\" raise NotImplementedError () # pragma: no cover MLModelException ( Exception ) Exception base class used to raise exceptions within MLModel derived classes. Source code in ml_base/ml_model.py class MLModelException ( Exception ): \"\"\"Exception base class used to raise exceptions within MLModel derived classes.\"\"\" def __init__ ( self , * args ): \"\"\"Initialize MLModelException instance.\"\"\" Exception . __init__ ( self , * args ) __init__ ( self , * args ) special Initialize MLModelException instance. Source code in ml_base/ml_model.py def __init__ ( self , * args ): \"\"\"Initialize MLModelException instance.\"\"\" Exception . __init__ ( self , * args ) MLModelSchemaValidationException ( MLModelException ) Exception type used to raise schema validation exceptions within MLModel derived classes. Source code in ml_base/ml_model.py class MLModelSchemaValidationException ( MLModelException ): \"\"\"Exception type used to raise schema validation exceptions within MLModel derived classes.\"\"\" def __init__ ( self , * args ): \"\"\"Initialize MLModelSchemaValidationException instance.\"\"\" MLModelException . __init__ ( self , * args ) __init__ ( self , * args ) special Initialize MLModelSchemaValidationException instance. Source code in ml_base/ml_model.py def __init__ ( self , * args ): \"\"\"Initialize MLModelSchemaValidationException instance.\"\"\" MLModelException . __init__ ( self , * args ) Base class for building decorators for MLModel objects. MLModelDecorator ( MLModel ) Base class for ML model decorator code. Note The default behavior of the MLModelDecorator base class is to do nothing and to forward the method call to the model that is is wrapping. Any subtypes of MLModelDecorator that would like to add on to the behavior of the model needs to override the default implementations in the MLModelDecorator base class. Source code in ml_base/decorator.py class MLModelDecorator ( MLModel ): \"\"\"Base class for ML model decorator code. !!! note The default behavior of the MLModelDecorator base class is to do nothing and to forward the method call to the model that is is wrapping. Any subtypes of MLModelDecorator that would like to add on to the behavior of the model needs to override the default implementations in the MLModelDecorator base class. \"\"\" _decorator_attributes = [ \"_model\" , \"_configuration\" ] def __init__ ( self , model : Optional [ MLModel ] = None , ** kwargs ): \"\"\"Initialize MLModelDecorator instance. !!! note The MLModel parameter is optional and does not need to be provided at initialization of the decorator instance. !!! note This method receives the model instance and stores the reference. \"\"\" if model is not None and not isinstance ( model , MLModel ): raise ValueError ( \"Only objects of type MLModel can be wrapped with MLModelDecorator instances.\" ) self . __dict__ [ \"_model\" ] = model self . __dict__ [ \"_configuration\" ] = kwargs def __repr__ ( self ): \"\"\"Return a string describing the decorator and the model that it is decorating.\"\"\" return \" {} ( {} )\" . format ( self . __class__ . __name__ , str ( self . __dict__ [ \"_model\" ])) def set_model ( self , model : MLModel ) -> \"MLModelDecorator\" : \"\"\"Set a model in the decorator instance.\"\"\" if not isinstance ( model , MLModel ): raise ValueError ( \"Only objects of type MLModel can be wrapped with MLModelDecorator instances.\" ) self . __dict__ [ \"_model\" ] = model return self def __getattr__ ( self , name ): \"\"\"Get an attribute.\"\"\" if name in MLModelDecorator . _decorator_attributes : return self . __dict__ [ name ] else : return getattr ( self . __dict__ [ \"_model\" ], name ) def __setattr__ ( self , name , value ): \"\"\"Set an attribute.\"\"\" if name in MLModelDecorator . _decorator_attributes : setattr ( self , name , value ) else : setattr ( self . __dict__ [ \"_model\" ], name , value ) def __delattr__ ( self , name ): \"\"\"Delete an attribute.\"\"\" delattr ( self . __dict__ [ \"_model\" ], name ) @property def display_name ( self ) -> str : \"\"\"Property that returns a display name for the model. !!! note Unless this method is overridden, the implementation just returns the display_name property of the model that is being decorated. \"\"\" return getattr ( self , \"_model\" ) . display_name @property def qualified_name ( self ) -> str : \"\"\"Property that returns the qualified name of the model. !!! note Unless this method is overridden, the implementation just returns the qualified_name property of the model that is being decorated. \"\"\" return getattr ( self , \"_model\" ) . qualified_name @property def description ( self ) -> str : \"\"\"Property that returns a description of the model. !!! note Unless this method is overridden, the implementation just returns the description property of the model that is being decorated. \"\"\" return getattr ( self , \"_model\" ) . description @property def version ( self ) -> str : \"\"\"Property that returns the model's version as a string. !!! note Unless this method is overridden, the implementation just returns the version property of the model that is being decorated. \"\"\" return getattr ( self , \"_model\" ) . version @property def input_schema ( self ): \"\"\"Property that returns the schema that is accepted by the predict() method. !!! note Unless this method is overridden, the implementation just returns the input_schema property of the model that is being decorated. \"\"\" return getattr ( self , \"_model\" ) . input_schema @property def output_schema ( self ): \"\"\"Property returns the schema that is returned by the predict() method. !!! note Unless this method is overridden, the implementation just returns the output_schema property of the model that is being decorated. \"\"\" return getattr ( self , \"_model\" ) . output_schema def predict ( self , data ): \"\"\"Predict with the model. Params: data: Data used by the model for making a prediction. Returns: python object -- can be any python type !!! note Unless this method is overridden, the implementation just calls the predict method of the model that is being decorated and returns the result. \"\"\" return getattr ( self , \"_model\" ) . predict ( data = data ) description : str property readonly Property that returns a description of the model. Note Unless this method is overridden, the implementation just returns the description property of the model that is being decorated. display_name : str property readonly Property that returns a display name for the model. Note Unless this method is overridden, the implementation just returns the display_name property of the model that is being decorated. input_schema property readonly Property that returns the schema that is accepted by the predict() method. Note Unless this method is overridden, the implementation just returns the input_schema property of the model that is being decorated. output_schema property readonly Property returns the schema that is returned by the predict() method. Note Unless this method is overridden, the implementation just returns the output_schema property of the model that is being decorated. qualified_name : str property readonly Property that returns the qualified name of the model. Note Unless this method is overridden, the implementation just returns the qualified_name property of the model that is being decorated. version : str property readonly Property that returns the model's version as a string. Note Unless this method is overridden, the implementation just returns the version property of the model that is being decorated. __delattr__ ( self , name ) special Delete an attribute. Source code in ml_base/decorator.py def __delattr__ ( self , name ): \"\"\"Delete an attribute.\"\"\" delattr ( self . __dict__ [ \"_model\" ], name ) __getattr__ ( self , name ) special Get an attribute. Source code in ml_base/decorator.py def __getattr__ ( self , name ): \"\"\"Get an attribute.\"\"\" if name in MLModelDecorator . _decorator_attributes : return self . __dict__ [ name ] else : return getattr ( self . __dict__ [ \"_model\" ], name ) __init__ ( self , model = None , ** kwargs ) special Initialize MLModelDecorator instance. Note The MLModel parameter is optional and does not need to be provided at initialization of the decorator instance. Note This method receives the model instance and stores the reference. Source code in ml_base/decorator.py def __init__ ( self , model : Optional [ MLModel ] = None , ** kwargs ): \"\"\"Initialize MLModelDecorator instance. !!! note The MLModel parameter is optional and does not need to be provided at initialization of the decorator instance. !!! note This method receives the model instance and stores the reference. \"\"\" if model is not None and not isinstance ( model , MLModel ): raise ValueError ( \"Only objects of type MLModel can be wrapped with MLModelDecorator instances.\" ) self . __dict__ [ \"_model\" ] = model self . __dict__ [ \"_configuration\" ] = kwargs __repr__ ( self ) special Return a string describing the decorator and the model that it is decorating. Source code in ml_base/decorator.py def __repr__ ( self ): \"\"\"Return a string describing the decorator and the model that it is decorating.\"\"\" return \" {} ( {} )\" . format ( self . __class__ . __name__ , str ( self . __dict__ [ \"_model\" ])) __setattr__ ( self , name , value ) special Set an attribute. Source code in ml_base/decorator.py def __setattr__ ( self , name , value ): \"\"\"Set an attribute.\"\"\" if name in MLModelDecorator . _decorator_attributes : setattr ( self , name , value ) else : setattr ( self . __dict__ [ \"_model\" ], name , value ) predict ( self , data ) Predict with the model. Parameters: Name Type Description Default data Data used by the model for making a prediction. required Returns: Type Description python object -- can be any python type Note Unless this method is overridden, the implementation just calls the predict method of the model that is being decorated and returns the result. Source code in ml_base/decorator.py def predict ( self , data ): \"\"\"Predict with the model. Params: data: Data used by the model for making a prediction. Returns: python object -- can be any python type !!! note Unless this method is overridden, the implementation just calls the predict method of the model that is being decorated and returns the result. \"\"\" return getattr ( self , \"_model\" ) . predict ( data = data ) set_model ( self , model ) Set a model in the decorator instance. Source code in ml_base/decorator.py def set_model ( self , model : MLModel ) -> \"MLModelDecorator\" : \"\"\"Set a model in the decorator instance.\"\"\" if not isinstance ( model , MLModel ): raise ValueError ( \"Only objects of type MLModel can be wrapped with MLModelDecorator instances.\" ) self . __dict__ [ \"_model\" ] = model return self Utilities Singleton class that instantiates and manages model objects. Source code in ml_base/utilities/model_manager.py class ModelManager ( object ): \"\"\"Singleton class that instantiates and manages model objects.\"\"\" def __new__ ( cls ): # noqa: D102 \"\"\"Create and return a new ModelManager instance, after instance is first created it will always be returned.\"\"\" if not hasattr ( cls , \"_instance\" ): cls . _instance = super ( ModelManager , cls ) . __new__ ( cls ) cls . _instance . _is_initialized = False return cls . _instance def __init__ ( self ): \"\"\"Construct ModelManager object.\"\"\" if self . _is_initialized is False : # pytype: disable=attribute-error self . _models = [] self . _is_initialized = True @classmethod def clear_instance ( cls ): \"\"\"Clear singleton instance from class.\"\"\" del cls . _instance def load_model ( self , class_path : str ) -> None : \"\"\"Import and instantiate an MLModel object from a class path. Args: class_path: Class path to the model's MLModel class. Raises: ValueError: Raised if the model is not a subtype of MLModel, or if a model with the same qualified name is already loaded in the ModelManager. \"\"\" # splitting the class_path into module path and class name module_path = \".\" . join ( class_path . split ( \".\" )[: - 1 ]) class_name = class_path . split ( \".\" )[ - 1 ] # importing the model class model_module = importlib . import_module ( module_path ) model_class = getattr ( model_module , class_name ) # instantiating the model object from the class model_object = model_class () self . add_model ( model_object ) def add_model ( self , model : MLModel ) -> None : \"\"\"Add a model to the ModelManager. Args: model: instance of MLModel \"\"\" if not isinstance ( model , MLModel ): raise ValueError ( \"ModelManager instance can only hold references to objects of type MLModel.\" ) if model . qualified_name in [ model . qualified_name for model in self . _models ]: raise ValueError ( \"A model with the same qualified name is already in the ModelManager singleton.\" ) # saving the model reference to the models list self . _models . append ( model ) def remove_model ( self , qualified_name : str ) -> None : \"\"\"Remove an MLModel object from the ModelManager singleton. Args: qualified_name: The qualified name of the model to be returned. Raises: ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton. \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) else : self . _models . remove ( model ) def get_models ( self ) -> List [ dict ]: \"\"\"Get a list of models in the model manager singleton. Returns: List of dictionaries containing information about the model instances in the ModelManager singleton. !!! note The dictionaries in the list returned by this method contain these keys: - display_name - qualified_name - description - version \"\"\" model_objects = [{ \"display_name\" : model . display_name , \"qualified_name\" : model . qualified_name , \"description\" : model . description , \"version\" : model . version } for model in self . _models ] return model_objects def get_model_metadata ( self , qualified_name : str ) -> dict : \"\"\"Get model metadata by qualified name. Args: qualified_name: Qualified name of the model for which to get metadata Returns: Dictionary containing information about a model in the ModelManager singleton. !!! note The dictionaries in the list returned by this method contain these keys: - display_name - qualified_name - description - version - input_schema - output_schema \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) else : return { \"display_name\" : model . display_name , \"qualified_name\" : model . qualified_name , \"description\" : model . description , \"version\" : model . version , \"input_schema\" : model . input_schema . schema (), \"output_schema\" : model . output_schema . schema () } def get_model ( self , qualified_name : str ) -> MLModel : \"\"\"Get a model object by qualified name. Args: qualified_name: The qualified name of the model to be returned. Returns: Model object Raises: ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton. \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) else : return model def add_decorator ( self , qualified_name : str , decorator : MLModelDecorator ) -> None : \"\"\"Add a decorator to a model object by qualified name. Args: qualified_name: The qualified name of the model to add decorator to. decorator: MLModelDecorator instance to apply to model instance. Returns: None Raises: ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton. \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) # removing old model reference self . remove_model ( qualified_name ) # adding the decorator to the model object decorated_model = decorator . set_model ( model ) # adding the decorated model to the collection self . add_model ( decorated_model ) __init__ ( self ) special Construct ModelManager object. Source code in ml_base/utilities/model_manager.py def __init__ ( self ): \"\"\"Construct ModelManager object.\"\"\" if self . _is_initialized is False : # pytype: disable=attribute-error self . _models = [] self . _is_initialized = True __new__ ( cls ) special staticmethod Create and return a new ModelManager instance, after instance is first created it will always be returned. Source code in ml_base/utilities/model_manager.py def __new__ ( cls ): # noqa: D102 \"\"\"Create and return a new ModelManager instance, after instance is first created it will always be returned.\"\"\" if not hasattr ( cls , \"_instance\" ): cls . _instance = super ( ModelManager , cls ) . __new__ ( cls ) cls . _instance . _is_initialized = False return cls . _instance add_decorator ( self , qualified_name , decorator ) Add a decorator to a model object by qualified name. Parameters: Name Type Description Default qualified_name str The qualified name of the model to add decorator to. required decorator MLModelDecorator MLModelDecorator instance to apply to model instance. required Returns: Type Description None None Exceptions: Type Description ValueError Raised if a model with the qualified name can't be found in the ModelManager singleton. Source code in ml_base/utilities/model_manager.py def add_decorator ( self , qualified_name : str , decorator : MLModelDecorator ) -> None : \"\"\"Add a decorator to a model object by qualified name. Args: qualified_name: The qualified name of the model to add decorator to. decorator: MLModelDecorator instance to apply to model instance. Returns: None Raises: ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton. \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) # removing old model reference self . remove_model ( qualified_name ) # adding the decorator to the model object decorated_model = decorator . set_model ( model ) # adding the decorated model to the collection self . add_model ( decorated_model ) add_model ( self , model ) Add a model to the ModelManager. Parameters: Name Type Description Default model MLModel instance of MLModel required Source code in ml_base/utilities/model_manager.py def add_model ( self , model : MLModel ) -> None : \"\"\"Add a model to the ModelManager. Args: model: instance of MLModel \"\"\" if not isinstance ( model , MLModel ): raise ValueError ( \"ModelManager instance can only hold references to objects of type MLModel.\" ) if model . qualified_name in [ model . qualified_name for model in self . _models ]: raise ValueError ( \"A model with the same qualified name is already in the ModelManager singleton.\" ) # saving the model reference to the models list self . _models . append ( model ) clear_instance () classmethod Clear singleton instance from class. Source code in ml_base/utilities/model_manager.py @classmethod def clear_instance ( cls ): \"\"\"Clear singleton instance from class.\"\"\" del cls . _instance get_model ( self , qualified_name ) Get a model object by qualified name. Parameters: Name Type Description Default qualified_name str The qualified name of the model to be returned. required Returns: Type Description MLModel Model object Exceptions: Type Description ValueError Raised if a model with the qualified name can't be found in the ModelManager singleton. Source code in ml_base/utilities/model_manager.py def get_model ( self , qualified_name : str ) -> MLModel : \"\"\"Get a model object by qualified name. Args: qualified_name: The qualified name of the model to be returned. Returns: Model object Raises: ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton. \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) else : return model get_model_metadata ( self , qualified_name ) Get model metadata by qualified name. Parameters: Name Type Description Default qualified_name str Qualified name of the model for which to get metadata required Returns: Type Description dict Dictionary containing information about a model in the ModelManager singleton. Note The dictionaries in the list returned by this method contain these keys: display_name qualified_name description version input_schema output_schema Source code in ml_base/utilities/model_manager.py def get_model_metadata ( self , qualified_name : str ) -> dict : \"\"\"Get model metadata by qualified name. Args: qualified_name: Qualified name of the model for which to get metadata Returns: Dictionary containing information about a model in the ModelManager singleton. !!! note The dictionaries in the list returned by this method contain these keys: - display_name - qualified_name - description - version - input_schema - output_schema \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) else : return { \"display_name\" : model . display_name , \"qualified_name\" : model . qualified_name , \"description\" : model . description , \"version\" : model . version , \"input_schema\" : model . input_schema . schema (), \"output_schema\" : model . output_schema . schema () } get_models ( self ) Get a list of models in the model manager singleton. Returns: Type Description List[dict] List of dictionaries containing information about the model instances in the ModelManager singleton. Note The dictionaries in the list returned by this method contain these keys: display_name qualified_name description version Source code in ml_base/utilities/model_manager.py def get_models ( self ) -> List [ dict ]: \"\"\"Get a list of models in the model manager singleton. Returns: List of dictionaries containing information about the model instances in the ModelManager singleton. !!! note The dictionaries in the list returned by this method contain these keys: - display_name - qualified_name - description - version \"\"\" model_objects = [{ \"display_name\" : model . display_name , \"qualified_name\" : model . qualified_name , \"description\" : model . description , \"version\" : model . version } for model in self . _models ] return model_objects load_model ( self , class_path ) Import and instantiate an MLModel object from a class path. Parameters: Name Type Description Default class_path str Class path to the model's MLModel class. required Exceptions: Type Description ValueError Raised if the model is not a subtype of MLModel, or if a model with the same qualified name is already loaded in the ModelManager. Source code in ml_base/utilities/model_manager.py def load_model ( self , class_path : str ) -> None : \"\"\"Import and instantiate an MLModel object from a class path. Args: class_path: Class path to the model's MLModel class. Raises: ValueError: Raised if the model is not a subtype of MLModel, or if a model with the same qualified name is already loaded in the ModelManager. \"\"\" # splitting the class_path into module path and class name module_path = \".\" . join ( class_path . split ( \".\" )[: - 1 ]) class_name = class_path . split ( \".\" )[ - 1 ] # importing the model class model_module = importlib . import_module ( module_path ) model_class = getattr ( model_module , class_name ) # instantiating the model object from the class model_object = model_class () self . add_model ( model_object ) remove_model ( self , qualified_name ) Remove an MLModel object from the ModelManager singleton. Parameters: Name Type Description Default qualified_name str The qualified name of the model to be returned. required Exceptions: Type Description ValueError Raised if a model with the qualified name can't be found in the ModelManager singleton. Source code in ml_base/utilities/model_manager.py def remove_model ( self , qualified_name : str ) -> None : \"\"\"Remove an MLModel object from the ModelManager singleton. Args: qualified_name: The qualified name of the model to be returned. Raises: ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton. \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) else : self . _models . remove ( model )","title":"API"},{"location":"api/#api-documentation","text":"","title":"API documentation"},{"location":"api/#base-classes","text":"Base class for building ML models that are easy to deploy and integrate.","title":"Base Classes"},{"location":"api/#ml_base.ml_model.MLModel","text":"Base class for ML model prediction code. Source code in ml_base/ml_model.py class MLModel ( ABC ): \"\"\"Base class for ML model prediction code.\"\"\" def __repr__ ( self ): \"\"\"Return a string representing the model object.\"\"\" return self . __class__ . __name__ @property @abstractmethod def display_name ( self ) -> str : \"\"\"Abstract property that returns a display name for the model. Returns: str: The display name of the model. !!! note This is a name for the model that looks good in user interfaces. \"\"\" raise NotImplementedError () # pragma: no cover @property @abstractmethod def qualified_name ( self ) -> str : \"\"\"Abstract property that returns the qualified name of the model. Returns: str: The qualified name of the model. !!! warning A qualified name is an unambiguous identifier for the model. \"\"\" raise NotImplementedError () # pragma: no cover @property @abstractmethod def description ( self ) -> str : \"\"\"Abstract property that returns a description of the model. Returns: str: The description of the model. \"\"\" raise NotImplementedError () # pragma: no cover @property @abstractmethod def version ( self ) -> str : \"\"\"Abstract property that returns the model's version as a string. Returns: str: The version of the model. \"\"\" raise NotImplementedError () # pragma: no cover @property @abstractmethod def input_schema ( self ): \"\"\"Property that returns the schema that is accepted by the predict() method. Returns: pydantic.BaseModel: The input schema of the model. !!! note This property must return a subtype of pydantic.BaseModel. \"\"\" raise NotImplementedError () # pragma: no cover @property @abstractmethod def output_schema ( self ): \"\"\"Property returns the schema that is returned by the predict() method. Returns: pydantic.BaseModel: The output schema of the model. !!! note This property must return a subtype of pydantic.BaseModel. \"\"\" raise NotImplementedError () # pragma: no cover @abstractmethod def __init__ ( self ) -> None : \"\"\"Create an MLModel instance by adding any deserialization and initialization code for the model.\"\"\" raise NotImplementedError () # pragma: no cover @abstractmethod def predict ( self , data ): \"\"\"Prediction with the model. Args: data: data used by the model for making a prediction Returns: object: can be any python type \"\"\" raise NotImplementedError () # pragma: no cover","title":"MLModel"},{"location":"api/#ml_base.ml_model.MLModel.description","text":"Abstract property that returns a description of the model. Returns: Type Description str The description of the model.","title":"description"},{"location":"api/#ml_base.ml_model.MLModel.display_name","text":"Abstract property that returns a display name for the model. Returns: Type Description str The display name of the model. Note This is a name for the model that looks good in user interfaces.","title":"display_name"},{"location":"api/#ml_base.ml_model.MLModel.input_schema","text":"Property that returns the schema that is accepted by the predict() method. Returns: Type Description pydantic.BaseModel The input schema of the model. Note This property must return a subtype of pydantic.BaseModel.","title":"input_schema"},{"location":"api/#ml_base.ml_model.MLModel.output_schema","text":"Property returns the schema that is returned by the predict() method. Returns: Type Description pydantic.BaseModel The output schema of the model. Note This property must return a subtype of pydantic.BaseModel.","title":"output_schema"},{"location":"api/#ml_base.ml_model.MLModel.qualified_name","text":"Abstract property that returns the qualified name of the model. Returns: Type Description str The qualified name of the model. Warning A qualified name is an unambiguous identifier for the model.","title":"qualified_name"},{"location":"api/#ml_base.ml_model.MLModel.version","text":"Abstract property that returns the model's version as a string. Returns: Type Description str The version of the model.","title":"version"},{"location":"api/#ml_base.ml_model.MLModel.__init__","text":"Create an MLModel instance by adding any deserialization and initialization code for the model. Source code in ml_base/ml_model.py @abstractmethod def __init__ ( self ) -> None : \"\"\"Create an MLModel instance by adding any deserialization and initialization code for the model.\"\"\" raise NotImplementedError () # pragma: no cover","title":"__init__()"},{"location":"api/#ml_base.ml_model.MLModel.__repr__","text":"Return a string representing the model object. Source code in ml_base/ml_model.py def __repr__ ( self ): \"\"\"Return a string representing the model object.\"\"\" return self . __class__ . __name__","title":"__repr__()"},{"location":"api/#ml_base.ml_model.MLModel.predict","text":"Prediction with the model. Parameters: Name Type Description Default data data used by the model for making a prediction required Returns: Type Description object can be any python type Source code in ml_base/ml_model.py @abstractmethod def predict ( self , data ): \"\"\"Prediction with the model. Args: data: data used by the model for making a prediction Returns: object: can be any python type \"\"\" raise NotImplementedError () # pragma: no cover","title":"predict()"},{"location":"api/#ml_base.ml_model.MLModelException","text":"Exception base class used to raise exceptions within MLModel derived classes. Source code in ml_base/ml_model.py class MLModelException ( Exception ): \"\"\"Exception base class used to raise exceptions within MLModel derived classes.\"\"\" def __init__ ( self , * args ): \"\"\"Initialize MLModelException instance.\"\"\" Exception . __init__ ( self , * args )","title":"MLModelException"},{"location":"api/#ml_base.ml_model.MLModelException.__init__","text":"Initialize MLModelException instance. Source code in ml_base/ml_model.py def __init__ ( self , * args ): \"\"\"Initialize MLModelException instance.\"\"\" Exception . __init__ ( self , * args )","title":"__init__()"},{"location":"api/#ml_base.ml_model.MLModelSchemaValidationException","text":"Exception type used to raise schema validation exceptions within MLModel derived classes. Source code in ml_base/ml_model.py class MLModelSchemaValidationException ( MLModelException ): \"\"\"Exception type used to raise schema validation exceptions within MLModel derived classes.\"\"\" def __init__ ( self , * args ): \"\"\"Initialize MLModelSchemaValidationException instance.\"\"\" MLModelException . __init__ ( self , * args )","title":"MLModelSchemaValidationException"},{"location":"api/#ml_base.ml_model.MLModelSchemaValidationException.__init__","text":"Initialize MLModelSchemaValidationException instance. Source code in ml_base/ml_model.py def __init__ ( self , * args ): \"\"\"Initialize MLModelSchemaValidationException instance.\"\"\" MLModelException . __init__ ( self , * args ) Base class for building decorators for MLModel objects.","title":"__init__()"},{"location":"api/#ml_base.decorator.MLModelDecorator","text":"Base class for ML model decorator code. Note The default behavior of the MLModelDecorator base class is to do nothing and to forward the method call to the model that is is wrapping. Any subtypes of MLModelDecorator that would like to add on to the behavior of the model needs to override the default implementations in the MLModelDecorator base class. Source code in ml_base/decorator.py class MLModelDecorator ( MLModel ): \"\"\"Base class for ML model decorator code. !!! note The default behavior of the MLModelDecorator base class is to do nothing and to forward the method call to the model that is is wrapping. Any subtypes of MLModelDecorator that would like to add on to the behavior of the model needs to override the default implementations in the MLModelDecorator base class. \"\"\" _decorator_attributes = [ \"_model\" , \"_configuration\" ] def __init__ ( self , model : Optional [ MLModel ] = None , ** kwargs ): \"\"\"Initialize MLModelDecorator instance. !!! note The MLModel parameter is optional and does not need to be provided at initialization of the decorator instance. !!! note This method receives the model instance and stores the reference. \"\"\" if model is not None and not isinstance ( model , MLModel ): raise ValueError ( \"Only objects of type MLModel can be wrapped with MLModelDecorator instances.\" ) self . __dict__ [ \"_model\" ] = model self . __dict__ [ \"_configuration\" ] = kwargs def __repr__ ( self ): \"\"\"Return a string describing the decorator and the model that it is decorating.\"\"\" return \" {} ( {} )\" . format ( self . __class__ . __name__ , str ( self . __dict__ [ \"_model\" ])) def set_model ( self , model : MLModel ) -> \"MLModelDecorator\" : \"\"\"Set a model in the decorator instance.\"\"\" if not isinstance ( model , MLModel ): raise ValueError ( \"Only objects of type MLModel can be wrapped with MLModelDecorator instances.\" ) self . __dict__ [ \"_model\" ] = model return self def __getattr__ ( self , name ): \"\"\"Get an attribute.\"\"\" if name in MLModelDecorator . _decorator_attributes : return self . __dict__ [ name ] else : return getattr ( self . __dict__ [ \"_model\" ], name ) def __setattr__ ( self , name , value ): \"\"\"Set an attribute.\"\"\" if name in MLModelDecorator . _decorator_attributes : setattr ( self , name , value ) else : setattr ( self . __dict__ [ \"_model\" ], name , value ) def __delattr__ ( self , name ): \"\"\"Delete an attribute.\"\"\" delattr ( self . __dict__ [ \"_model\" ], name ) @property def display_name ( self ) -> str : \"\"\"Property that returns a display name for the model. !!! note Unless this method is overridden, the implementation just returns the display_name property of the model that is being decorated. \"\"\" return getattr ( self , \"_model\" ) . display_name @property def qualified_name ( self ) -> str : \"\"\"Property that returns the qualified name of the model. !!! note Unless this method is overridden, the implementation just returns the qualified_name property of the model that is being decorated. \"\"\" return getattr ( self , \"_model\" ) . qualified_name @property def description ( self ) -> str : \"\"\"Property that returns a description of the model. !!! note Unless this method is overridden, the implementation just returns the description property of the model that is being decorated. \"\"\" return getattr ( self , \"_model\" ) . description @property def version ( self ) -> str : \"\"\"Property that returns the model's version as a string. !!! note Unless this method is overridden, the implementation just returns the version property of the model that is being decorated. \"\"\" return getattr ( self , \"_model\" ) . version @property def input_schema ( self ): \"\"\"Property that returns the schema that is accepted by the predict() method. !!! note Unless this method is overridden, the implementation just returns the input_schema property of the model that is being decorated. \"\"\" return getattr ( self , \"_model\" ) . input_schema @property def output_schema ( self ): \"\"\"Property returns the schema that is returned by the predict() method. !!! note Unless this method is overridden, the implementation just returns the output_schema property of the model that is being decorated. \"\"\" return getattr ( self , \"_model\" ) . output_schema def predict ( self , data ): \"\"\"Predict with the model. Params: data: Data used by the model for making a prediction. Returns: python object -- can be any python type !!! note Unless this method is overridden, the implementation just calls the predict method of the model that is being decorated and returns the result. \"\"\" return getattr ( self , \"_model\" ) . predict ( data = data )","title":"MLModelDecorator"},{"location":"api/#ml_base.decorator.MLModelDecorator.description","text":"Property that returns a description of the model. Note Unless this method is overridden, the implementation just returns the description property of the model that is being decorated.","title":"description"},{"location":"api/#ml_base.decorator.MLModelDecorator.display_name","text":"Property that returns a display name for the model. Note Unless this method is overridden, the implementation just returns the display_name property of the model that is being decorated.","title":"display_name"},{"location":"api/#ml_base.decorator.MLModelDecorator.input_schema","text":"Property that returns the schema that is accepted by the predict() method. Note Unless this method is overridden, the implementation just returns the input_schema property of the model that is being decorated.","title":"input_schema"},{"location":"api/#ml_base.decorator.MLModelDecorator.output_schema","text":"Property returns the schema that is returned by the predict() method. Note Unless this method is overridden, the implementation just returns the output_schema property of the model that is being decorated.","title":"output_schema"},{"location":"api/#ml_base.decorator.MLModelDecorator.qualified_name","text":"Property that returns the qualified name of the model. Note Unless this method is overridden, the implementation just returns the qualified_name property of the model that is being decorated.","title":"qualified_name"},{"location":"api/#ml_base.decorator.MLModelDecorator.version","text":"Property that returns the model's version as a string. Note Unless this method is overridden, the implementation just returns the version property of the model that is being decorated.","title":"version"},{"location":"api/#ml_base.decorator.MLModelDecorator.__delattr__","text":"Delete an attribute. Source code in ml_base/decorator.py def __delattr__ ( self , name ): \"\"\"Delete an attribute.\"\"\" delattr ( self . __dict__ [ \"_model\" ], name )","title":"__delattr__()"},{"location":"api/#ml_base.decorator.MLModelDecorator.__getattr__","text":"Get an attribute. Source code in ml_base/decorator.py def __getattr__ ( self , name ): \"\"\"Get an attribute.\"\"\" if name in MLModelDecorator . _decorator_attributes : return self . __dict__ [ name ] else : return getattr ( self . __dict__ [ \"_model\" ], name )","title":"__getattr__()"},{"location":"api/#ml_base.decorator.MLModelDecorator.__init__","text":"Initialize MLModelDecorator instance. Note The MLModel parameter is optional and does not need to be provided at initialization of the decorator instance. Note This method receives the model instance and stores the reference. Source code in ml_base/decorator.py def __init__ ( self , model : Optional [ MLModel ] = None , ** kwargs ): \"\"\"Initialize MLModelDecorator instance. !!! note The MLModel parameter is optional and does not need to be provided at initialization of the decorator instance. !!! note This method receives the model instance and stores the reference. \"\"\" if model is not None and not isinstance ( model , MLModel ): raise ValueError ( \"Only objects of type MLModel can be wrapped with MLModelDecorator instances.\" ) self . __dict__ [ \"_model\" ] = model self . __dict__ [ \"_configuration\" ] = kwargs","title":"__init__()"},{"location":"api/#ml_base.decorator.MLModelDecorator.__repr__","text":"Return a string describing the decorator and the model that it is decorating. Source code in ml_base/decorator.py def __repr__ ( self ): \"\"\"Return a string describing the decorator and the model that it is decorating.\"\"\" return \" {} ( {} )\" . format ( self . __class__ . __name__ , str ( self . __dict__ [ \"_model\" ]))","title":"__repr__()"},{"location":"api/#ml_base.decorator.MLModelDecorator.__setattr__","text":"Set an attribute. Source code in ml_base/decorator.py def __setattr__ ( self , name , value ): \"\"\"Set an attribute.\"\"\" if name in MLModelDecorator . _decorator_attributes : setattr ( self , name , value ) else : setattr ( self . __dict__ [ \"_model\" ], name , value )","title":"__setattr__()"},{"location":"api/#ml_base.decorator.MLModelDecorator.predict","text":"Predict with the model. Parameters: Name Type Description Default data Data used by the model for making a prediction. required Returns: Type Description python object -- can be any python type Note Unless this method is overridden, the implementation just calls the predict method of the model that is being decorated and returns the result. Source code in ml_base/decorator.py def predict ( self , data ): \"\"\"Predict with the model. Params: data: Data used by the model for making a prediction. Returns: python object -- can be any python type !!! note Unless this method is overridden, the implementation just calls the predict method of the model that is being decorated and returns the result. \"\"\" return getattr ( self , \"_model\" ) . predict ( data = data )","title":"predict()"},{"location":"api/#ml_base.decorator.MLModelDecorator.set_model","text":"Set a model in the decorator instance. Source code in ml_base/decorator.py def set_model ( self , model : MLModel ) -> \"MLModelDecorator\" : \"\"\"Set a model in the decorator instance.\"\"\" if not isinstance ( model , MLModel ): raise ValueError ( \"Only objects of type MLModel can be wrapped with MLModelDecorator instances.\" ) self . __dict__ [ \"_model\" ] = model return self","title":"set_model()"},{"location":"api/#utilities","text":"Singleton class that instantiates and manages model objects. Source code in ml_base/utilities/model_manager.py class ModelManager ( object ): \"\"\"Singleton class that instantiates and manages model objects.\"\"\" def __new__ ( cls ): # noqa: D102 \"\"\"Create and return a new ModelManager instance, after instance is first created it will always be returned.\"\"\" if not hasattr ( cls , \"_instance\" ): cls . _instance = super ( ModelManager , cls ) . __new__ ( cls ) cls . _instance . _is_initialized = False return cls . _instance def __init__ ( self ): \"\"\"Construct ModelManager object.\"\"\" if self . _is_initialized is False : # pytype: disable=attribute-error self . _models = [] self . _is_initialized = True @classmethod def clear_instance ( cls ): \"\"\"Clear singleton instance from class.\"\"\" del cls . _instance def load_model ( self , class_path : str ) -> None : \"\"\"Import and instantiate an MLModel object from a class path. Args: class_path: Class path to the model's MLModel class. Raises: ValueError: Raised if the model is not a subtype of MLModel, or if a model with the same qualified name is already loaded in the ModelManager. \"\"\" # splitting the class_path into module path and class name module_path = \".\" . join ( class_path . split ( \".\" )[: - 1 ]) class_name = class_path . split ( \".\" )[ - 1 ] # importing the model class model_module = importlib . import_module ( module_path ) model_class = getattr ( model_module , class_name ) # instantiating the model object from the class model_object = model_class () self . add_model ( model_object ) def add_model ( self , model : MLModel ) -> None : \"\"\"Add a model to the ModelManager. Args: model: instance of MLModel \"\"\" if not isinstance ( model , MLModel ): raise ValueError ( \"ModelManager instance can only hold references to objects of type MLModel.\" ) if model . qualified_name in [ model . qualified_name for model in self . _models ]: raise ValueError ( \"A model with the same qualified name is already in the ModelManager singleton.\" ) # saving the model reference to the models list self . _models . append ( model ) def remove_model ( self , qualified_name : str ) -> None : \"\"\"Remove an MLModel object from the ModelManager singleton. Args: qualified_name: The qualified name of the model to be returned. Raises: ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton. \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) else : self . _models . remove ( model ) def get_models ( self ) -> List [ dict ]: \"\"\"Get a list of models in the model manager singleton. Returns: List of dictionaries containing information about the model instances in the ModelManager singleton. !!! note The dictionaries in the list returned by this method contain these keys: - display_name - qualified_name - description - version \"\"\" model_objects = [{ \"display_name\" : model . display_name , \"qualified_name\" : model . qualified_name , \"description\" : model . description , \"version\" : model . version } for model in self . _models ] return model_objects def get_model_metadata ( self , qualified_name : str ) -> dict : \"\"\"Get model metadata by qualified name. Args: qualified_name: Qualified name of the model for which to get metadata Returns: Dictionary containing information about a model in the ModelManager singleton. !!! note The dictionaries in the list returned by this method contain these keys: - display_name - qualified_name - description - version - input_schema - output_schema \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) else : return { \"display_name\" : model . display_name , \"qualified_name\" : model . qualified_name , \"description\" : model . description , \"version\" : model . version , \"input_schema\" : model . input_schema . schema (), \"output_schema\" : model . output_schema . schema () } def get_model ( self , qualified_name : str ) -> MLModel : \"\"\"Get a model object by qualified name. Args: qualified_name: The qualified name of the model to be returned. Returns: Model object Raises: ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton. \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) else : return model def add_decorator ( self , qualified_name : str , decorator : MLModelDecorator ) -> None : \"\"\"Add a decorator to a model object by qualified name. Args: qualified_name: The qualified name of the model to add decorator to. decorator: MLModelDecorator instance to apply to model instance. Returns: None Raises: ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton. \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) # removing old model reference self . remove_model ( qualified_name ) # adding the decorator to the model object decorated_model = decorator . set_model ( model ) # adding the decorated model to the collection self . add_model ( decorated_model )","title":"Utilities"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.__init__","text":"Construct ModelManager object. Source code in ml_base/utilities/model_manager.py def __init__ ( self ): \"\"\"Construct ModelManager object.\"\"\" if self . _is_initialized is False : # pytype: disable=attribute-error self . _models = [] self . _is_initialized = True","title":"__init__()"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.__new__","text":"Create and return a new ModelManager instance, after instance is first created it will always be returned. Source code in ml_base/utilities/model_manager.py def __new__ ( cls ): # noqa: D102 \"\"\"Create and return a new ModelManager instance, after instance is first created it will always be returned.\"\"\" if not hasattr ( cls , \"_instance\" ): cls . _instance = super ( ModelManager , cls ) . __new__ ( cls ) cls . _instance . _is_initialized = False return cls . _instance","title":"__new__()"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.add_decorator","text":"Add a decorator to a model object by qualified name. Parameters: Name Type Description Default qualified_name str The qualified name of the model to add decorator to. required decorator MLModelDecorator MLModelDecorator instance to apply to model instance. required Returns: Type Description None None Exceptions: Type Description ValueError Raised if a model with the qualified name can't be found in the ModelManager singleton. Source code in ml_base/utilities/model_manager.py def add_decorator ( self , qualified_name : str , decorator : MLModelDecorator ) -> None : \"\"\"Add a decorator to a model object by qualified name. Args: qualified_name: The qualified name of the model to add decorator to. decorator: MLModelDecorator instance to apply to model instance. Returns: None Raises: ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton. \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) # removing old model reference self . remove_model ( qualified_name ) # adding the decorator to the model object decorated_model = decorator . set_model ( model ) # adding the decorated model to the collection self . add_model ( decorated_model )","title":"add_decorator()"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.add_model","text":"Add a model to the ModelManager. Parameters: Name Type Description Default model MLModel instance of MLModel required Source code in ml_base/utilities/model_manager.py def add_model ( self , model : MLModel ) -> None : \"\"\"Add a model to the ModelManager. Args: model: instance of MLModel \"\"\" if not isinstance ( model , MLModel ): raise ValueError ( \"ModelManager instance can only hold references to objects of type MLModel.\" ) if model . qualified_name in [ model . qualified_name for model in self . _models ]: raise ValueError ( \"A model with the same qualified name is already in the ModelManager singleton.\" ) # saving the model reference to the models list self . _models . append ( model )","title":"add_model()"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.clear_instance","text":"Clear singleton instance from class. Source code in ml_base/utilities/model_manager.py @classmethod def clear_instance ( cls ): \"\"\"Clear singleton instance from class.\"\"\" del cls . _instance","title":"clear_instance()"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.get_model","text":"Get a model object by qualified name. Parameters: Name Type Description Default qualified_name str The qualified name of the model to be returned. required Returns: Type Description MLModel Model object Exceptions: Type Description ValueError Raised if a model with the qualified name can't be found in the ModelManager singleton. Source code in ml_base/utilities/model_manager.py def get_model ( self , qualified_name : str ) -> MLModel : \"\"\"Get a model object by qualified name. Args: qualified_name: The qualified name of the model to be returned. Returns: Model object Raises: ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton. \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) else : return model","title":"get_model()"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.get_model_metadata","text":"Get model metadata by qualified name. Parameters: Name Type Description Default qualified_name str Qualified name of the model for which to get metadata required Returns: Type Description dict Dictionary containing information about a model in the ModelManager singleton. Note The dictionaries in the list returned by this method contain these keys: display_name qualified_name description version input_schema output_schema Source code in ml_base/utilities/model_manager.py def get_model_metadata ( self , qualified_name : str ) -> dict : \"\"\"Get model metadata by qualified name. Args: qualified_name: Qualified name of the model for which to get metadata Returns: Dictionary containing information about a model in the ModelManager singleton. !!! note The dictionaries in the list returned by this method contain these keys: - display_name - qualified_name - description - version - input_schema - output_schema \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) else : return { \"display_name\" : model . display_name , \"qualified_name\" : model . qualified_name , \"description\" : model . description , \"version\" : model . version , \"input_schema\" : model . input_schema . schema (), \"output_schema\" : model . output_schema . schema () }","title":"get_model_metadata()"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.get_models","text":"Get a list of models in the model manager singleton. Returns: Type Description List[dict] List of dictionaries containing information about the model instances in the ModelManager singleton. Note The dictionaries in the list returned by this method contain these keys: display_name qualified_name description version Source code in ml_base/utilities/model_manager.py def get_models ( self ) -> List [ dict ]: \"\"\"Get a list of models in the model manager singleton. Returns: List of dictionaries containing information about the model instances in the ModelManager singleton. !!! note The dictionaries in the list returned by this method contain these keys: - display_name - qualified_name - description - version \"\"\" model_objects = [{ \"display_name\" : model . display_name , \"qualified_name\" : model . qualified_name , \"description\" : model . description , \"version\" : model . version } for model in self . _models ] return model_objects","title":"get_models()"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.load_model","text":"Import and instantiate an MLModel object from a class path. Parameters: Name Type Description Default class_path str Class path to the model's MLModel class. required Exceptions: Type Description ValueError Raised if the model is not a subtype of MLModel, or if a model with the same qualified name is already loaded in the ModelManager. Source code in ml_base/utilities/model_manager.py def load_model ( self , class_path : str ) -> None : \"\"\"Import and instantiate an MLModel object from a class path. Args: class_path: Class path to the model's MLModel class. Raises: ValueError: Raised if the model is not a subtype of MLModel, or if a model with the same qualified name is already loaded in the ModelManager. \"\"\" # splitting the class_path into module path and class name module_path = \".\" . join ( class_path . split ( \".\" )[: - 1 ]) class_name = class_path . split ( \".\" )[ - 1 ] # importing the model class model_module = importlib . import_module ( module_path ) model_class = getattr ( model_module , class_name ) # instantiating the model object from the class model_object = model_class () self . add_model ( model_object )","title":"load_model()"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.remove_model","text":"Remove an MLModel object from the ModelManager singleton. Parameters: Name Type Description Default qualified_name str The qualified name of the model to be returned. required Exceptions: Type Description ValueError Raised if a model with the qualified name can't be found in the ModelManager singleton. Source code in ml_base/utilities/model_manager.py def remove_model ( self , qualified_name : str ) -> None : \"\"\"Remove an MLModel object from the ModelManager singleton. Args: qualified_name: The qualified name of the model to be returned. Raises: ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton. \"\"\" # searching the list of model objects to find the one with the right qualified name model = next (( model for model in self . _models if model . qualified_name == qualified_name ), None ) if model is None : raise ValueError ( \"Instance of model ' {} ' not found in ModelManager.\" . format ( qualified_name )) else : self . _models . remove ( model )","title":"remove_model()"},{"location":"basic/","text":"Introducing the ml_base Package These examples run within an Jupyter notebook session. To clear out the results of cells that we don't want to see we'll use the clear_output() function provided by Jupyter: from IPython.display import clear_output To get started we'll install the ml_base package: !pip install ml_base clear_output() Creating a Simple Model To show how to work with the MLModel base class we'll create a simple model that we can make predictions with. We'll use the scikit-learn library, so we'll need to install it: !pip install scikit-learn clear_output() Now we can write some code to train a model: from sklearn import datasets from sklearn import svm import pickle # loading the Iris dataset iris = datasets.load_iris() # instantiating an SVM model from scikit-learn svm_model = svm.SVC(gamma=1.0, C=1.0) # fitting the model svm_model.fit(iris.data[:-1], iris.target[:-1]) # serializing the model and saving it file = open(\"svc_model.pickle\", 'wb') pickle.dump(svm_model, file) file.close() Creating a Wrapper Class for Your Model Now that we have a model object, we'll define a class that implements the prediction functionality for the code: import os from numpy import array class IrisModel(object): def __init__(self): dir_path = os.path.abspath('') file = open(os.path.join(dir_path, \"svc_model.pickle\"), 'rb') self._svm_model = pickle.load(file) file.close() def predict(self, data: dict): X = array([data[\"sepal_length\"], data[\"sepal_width\"], data[\"petal_length\"], data[\"petal_width\"]]).reshape(1, -1) y_hat = int(self._svm_model.predict(X)[0]) targets = ['setosa', 'versicolor', 'virginica'] species = targets[y_hat] return {\"species\": species} The class above wraps the pickled model object and makes the model easier to use by converting the inputs and outputs. To use the model, all we need to do is this: model = IrisModel() prediction = model.predict(data={ \"sepal_length\":1.0, \"sepal_width\":1.1, \"petal_length\": 1.2, \"petal_width\": 1.3}) prediction {'species': 'virginica'} Creating an MLModel Class for Your Model The model is already much easier to use because it provides the prediction from a class. The user of the model doesn't need to worry about loading the pickled model object, or converting the model's input into a numpy array. However, we are still not using the MLModel abstract base class, now we'll implement a part of the MLModel's interface to show how it works: from ml_base import MLModel class IrisModel(MLModel): @property def display_name(self): return \"Iris Model\" @property def qualified_name(self): return \"iris_model\" @property def description(self): return \"A model to predict the species of a flower based on its measurements.\" @property def version(self): return \"1.0.0\" @property def input_schema(self): raise NotImplementedError() @property def output_schema(self): raise NotImplementedError() def __init__(self): dir_path = os.path.abspath('') file = open(os.path.join(dir_path, \"svc_model.pickle\"), 'rb') self._svm_model = pickle.load(file) file.close() def predict(self, data: dict): X = array([data[\"sepal_length\"], data[\"sepal_width\"], data[\"petal_length\"], data[\"petal_width\"]]).reshape(1, -1) y_hat = int(self._svm_model.predict(X)[0]) targets = ['setosa', 'versicolor', 'virginica'] species = targets[y_hat] return {\"species\": species} The MLModel base class defines a set of properties that must be provided by any class that inherits from it. Because the IrisModel class now provides this metadata about the model, we can access it directly from the model object like this: model = IrisModel() print(model.qualified_name) iris_model The qualified name of the model uniquely identifies the instance of the model within the system. Right now the qualified name is hardcoded in the code of the model's class, but this can be made more dynamic in the future. The qualified name should also be a string that is easy to embed in a URL, so it shouldn't have spaces or special characters. The model's display name is also available from the model object: print(model.display_name) Iris Model The display name of a model should be a string that looks good in a user interface. The model description is also available from the model object: print(model.description) A model to predict the species of a flower based on its measurements. The model version is also available as a string from the model object: print(model.version) 1.0.0 As you can see, we didn't implement the input_schema and output_schema properties above, we'll add those next. Adding Schemas to Your Model To add schema information to the model class, we'll use the pydantic package. The pydantic package allows us to state the schema requirements of the model's input and output programatically as Python classes: from pydantic import BaseModel, Field from pydantic import ValidationError from enum import Enum class ModelInput(BaseModel): sepal_length: float = Field(gt=5.0, lt=8.0, description=\"The length of the sepal of the flower.\") sepal_width: float = Field(gt=2.0, lt=6.0, description=\"The width of the sepal of the flower.\") petal_length: float = Field(gt=1.0, lt=6.8, description=\"The length of the petal of the flower.\") petal_width: float = Field(gt=0.0, lt=3.0, description=\"The width of the petal of the flower.\") class Species(str, Enum): iris_setosa = \"Iris setosa\" iris_versicolor = \"Iris versicolor\" iris_virginica = \"Iris virginica\" class ModelOutput(BaseModel): species: Species = Field(description=\"The predicted species of the flower.\") The ModelInput class inherits from the pydantic BaseModel class and it defines four required fields, all of them floating point numbers. The pydantic package allows for defining upper bounds and lower bounds for the values accepted by each field, and also a description for the field. The ModelOutput is made up of a single fields, which is an enumerated string that contains the predicted species of the flower. Now that we have the ModelInput and ModelOutput schemas defined as pydantic BaseModel classes, we'll add them to the IrisModel class by returning them from the input_schema and output_schema properties: from ml_base.ml_model import MLModel, MLModelSchemaValidationException class IrisModel(MLModel): @property def display_name(self): return \"Iris Model\" @property def qualified_name(self): return \"iris_model\" @property def description(self): return \"A model to predict the species of a flower based on its measurements.\" @property def version(self): return \"1.0.0\" @property def input_schema(self): return ModelInput @property def output_schema(self): return ModelOutput def __init__(self): dir_path = os.path.abspath('') with open(os.path.join(dir_path, \"svc_model.pickle\"), 'rb') as f: self._svm_model = pickle.load(f) def predict(self, data: ModelInput): # creating a numpy array using the fields in the input object X = array([data.sepal_length, data.sepal_width, data.petal_length, data.petal_width]).reshape(1, -1) # making a prediction, at this point its a number y_hat = int(self._svm_model.predict(X)[0]) # converting the prediction from a number to a string targets = [\"Iris setosa\", \"Iris versicolor\", \"Iris virginica\"] species = targets[y_hat] # returning the prediction inside an object return ModelOutput(species=species) Notice that we are also using the pydantic models to validate the input before prediction and to create an object that will be returned from the model's predict() method. If we use the model class now, we'll get this result: model = IrisModel() prediction = model.predict(ModelInput( sepal_length=6.0, sepal_width=2.1, petal_length=1.2, petal_width=1.3)) prediction ModelOutput(species=<Species.iris_virginica: 'Iris virginica'>) By adding input and output schemas to the model, we can automate many other operations later. Also, we can query the model object itself for the schema. The pydantic package is able to create JSON schema from the fields in the input and output schema objects of the model: model = IrisModel() model.input_schema.schema() {'title': 'ModelInput', 'type': 'object', 'properties': {'sepal_length': {'title': 'Sepal Length', 'description': 'The length of the sepal of the flower.', 'exclusiveMinimum': 5.0, 'exclusiveMaximum': 8.0, 'type': 'number'}, 'sepal_width': {'title': 'Sepal Width', 'description': 'The width of the sepal of the flower.', 'exclusiveMinimum': 2.0, 'exclusiveMaximum': 6.0, 'type': 'number'}, 'petal_length': {'title': 'Petal Length', 'description': 'The length of the petal of the flower.', 'exclusiveMinimum': 1.0, 'exclusiveMaximum': 6.8, 'type': 'number'}, 'petal_width': {'title': 'Petal Width', 'description': 'The width of the petal of the flower.', 'exclusiveMinimum': 0.0, 'exclusiveMaximum': 3.0, 'type': 'number'}}, 'required': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']} model.output_schema.schema() {'title': 'ModelOutput', 'type': 'object', 'properties': {'species': {'$ref': '#/definitions/Species'}}, 'required': ['species'], 'definitions': {'Species': {'title': 'Species', 'description': 'An enumeration.', 'enum': ['Iris setosa', 'Iris versicolor', 'Iris virginica'], 'type': 'string'}}} Although it is not required to use the pydantic package to create model schemas, it is recommended. The pydantic package is installed as a dependency of the ml_base package. Using the ModelManager Class The ModelManager class is provided to help manage model objects. It is a singleton class that is designed to enable model instances to be instantiated once during the lifecycle of a process and accessed many times: from ml_base.utilities import ModelManager model_manager = ModelManager() Because it is a singleton object, a reference to the same object is returned no matter how many times we instantiate it: print(id(model_manager)) another_model_manager = ModelManager() print(id(another_model_manager)) 4505980208 4505980208 You can add model instances to the ModelManager singleton by asking it to instantiate the model class: model_manager.load_model(\"__main__.IrisModel\") The load_model() method is able to find the MLModel class that we defined above and instantiate it, after that it stores a reference to the instance internally. The ModelManager is also able to save references to model instances that were instantiated in some other way by using the add_model() method: another_iris_model = IrisModel() try: model_manager.add_model(another_iris_model) except ValueError as e: print(e) A model with the same qualified name is already in the ModelManager singleton. In this case, the ModelManager did not save the instance of the IrisModel because we already had an instance of the model. The models are uniquely identified by their qualified name properties. The ModelManager instance can list the models that it contains with the get_models() method, the details of the instance of IrisModel that we just created are returned: model_manager.get_models() [{'display_name': 'Iris Model', 'qualified_name': 'iris_model', 'description': 'A model to predict the species of a flower based on its measurements.', 'version': '1.0.0'}] The ModelManager instance can return the metadata of any of the models. The metadata includes the input and output schemas as well: model_manager.get_model_metadata(\"iris_model\") {'display_name': 'Iris Model', 'qualified_name': 'iris_model', 'description': 'A model to predict the species of a flower based on its measurements.', 'version': '1.0.0', 'input_schema': {'title': 'ModelInput', 'type': 'object', 'properties': {'sepal_length': {'title': 'Sepal Length', 'description': 'The length of the sepal of the flower.', 'exclusiveMinimum': 5.0, 'exclusiveMaximum': 8.0, 'type': 'number'}, 'sepal_width': {'title': 'Sepal Width', 'description': 'The width of the sepal of the flower.', 'exclusiveMinimum': 2.0, 'exclusiveMaximum': 6.0, 'type': 'number'}, 'petal_length': {'title': 'Petal Length', 'description': 'The length of the petal of the flower.', 'exclusiveMinimum': 1.0, 'exclusiveMaximum': 6.8, 'type': 'number'}, 'petal_width': {'title': 'Petal Width', 'description': 'The width of the petal of the flower.', 'exclusiveMinimum': 0.0, 'exclusiveMaximum': 3.0, 'type': 'number'}}, 'required': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']}, 'output_schema': {'title': 'ModelOutput', 'type': 'object', 'properties': {'species': {'$ref': '#/definitions/Species'}}, 'required': ['species'], 'definitions': {'Species': {'title': 'Species', 'description': 'An enumeration.', 'enum': ['Iris setosa', 'Iris versicolor', 'Iris virginica'], 'type': 'string'}}}} The ModelManager can return a reference to the instance of any model that it is holding: iris_model = model_manager.get_model(\"iris_model\") print(iris_model.display_name) Iris Model The instance is identified by the qualified name of the model. Lastly, a model instance can be removed by calling the remove_model() method: model_manager.remove_model(\"iris_model\") model_manager.get_models() [] To clear the ModelManager instance, you can call the clear_instance() method: model_manager.clear_instance() To create a new singleton you have to instantiate the ModelManager again: model_manager = ModelManager()","title":"Basic Examples"},{"location":"basic/#introducing-the-ml_base-package","text":"These examples run within an Jupyter notebook session. To clear out the results of cells that we don't want to see we'll use the clear_output() function provided by Jupyter: from IPython.display import clear_output To get started we'll install the ml_base package: !pip install ml_base clear_output()","title":"Introducing the ml_base Package"},{"location":"basic/#creating-a-simple-model","text":"To show how to work with the MLModel base class we'll create a simple model that we can make predictions with. We'll use the scikit-learn library, so we'll need to install it: !pip install scikit-learn clear_output() Now we can write some code to train a model: from sklearn import datasets from sklearn import svm import pickle # loading the Iris dataset iris = datasets.load_iris() # instantiating an SVM model from scikit-learn svm_model = svm.SVC(gamma=1.0, C=1.0) # fitting the model svm_model.fit(iris.data[:-1], iris.target[:-1]) # serializing the model and saving it file = open(\"svc_model.pickle\", 'wb') pickle.dump(svm_model, file) file.close()","title":"Creating a Simple Model"},{"location":"basic/#creating-a-wrapper-class-for-your-model","text":"Now that we have a model object, we'll define a class that implements the prediction functionality for the code: import os from numpy import array class IrisModel(object): def __init__(self): dir_path = os.path.abspath('') file = open(os.path.join(dir_path, \"svc_model.pickle\"), 'rb') self._svm_model = pickle.load(file) file.close() def predict(self, data: dict): X = array([data[\"sepal_length\"], data[\"sepal_width\"], data[\"petal_length\"], data[\"petal_width\"]]).reshape(1, -1) y_hat = int(self._svm_model.predict(X)[0]) targets = ['setosa', 'versicolor', 'virginica'] species = targets[y_hat] return {\"species\": species} The class above wraps the pickled model object and makes the model easier to use by converting the inputs and outputs. To use the model, all we need to do is this: model = IrisModel() prediction = model.predict(data={ \"sepal_length\":1.0, \"sepal_width\":1.1, \"petal_length\": 1.2, \"petal_width\": 1.3}) prediction {'species': 'virginica'}","title":"Creating a Wrapper Class for Your Model"},{"location":"basic/#creating-an-mlmodel-class-for-your-model","text":"The model is already much easier to use because it provides the prediction from a class. The user of the model doesn't need to worry about loading the pickled model object, or converting the model's input into a numpy array. However, we are still not using the MLModel abstract base class, now we'll implement a part of the MLModel's interface to show how it works: from ml_base import MLModel class IrisModel(MLModel): @property def display_name(self): return \"Iris Model\" @property def qualified_name(self): return \"iris_model\" @property def description(self): return \"A model to predict the species of a flower based on its measurements.\" @property def version(self): return \"1.0.0\" @property def input_schema(self): raise NotImplementedError() @property def output_schema(self): raise NotImplementedError() def __init__(self): dir_path = os.path.abspath('') file = open(os.path.join(dir_path, \"svc_model.pickle\"), 'rb') self._svm_model = pickle.load(file) file.close() def predict(self, data: dict): X = array([data[\"sepal_length\"], data[\"sepal_width\"], data[\"petal_length\"], data[\"petal_width\"]]).reshape(1, -1) y_hat = int(self._svm_model.predict(X)[0]) targets = ['setosa', 'versicolor', 'virginica'] species = targets[y_hat] return {\"species\": species} The MLModel base class defines a set of properties that must be provided by any class that inherits from it. Because the IrisModel class now provides this metadata about the model, we can access it directly from the model object like this: model = IrisModel() print(model.qualified_name) iris_model The qualified name of the model uniquely identifies the instance of the model within the system. Right now the qualified name is hardcoded in the code of the model's class, but this can be made more dynamic in the future. The qualified name should also be a string that is easy to embed in a URL, so it shouldn't have spaces or special characters. The model's display name is also available from the model object: print(model.display_name) Iris Model The display name of a model should be a string that looks good in a user interface. The model description is also available from the model object: print(model.description) A model to predict the species of a flower based on its measurements. The model version is also available as a string from the model object: print(model.version) 1.0.0 As you can see, we didn't implement the input_schema and output_schema properties above, we'll add those next.","title":"Creating an MLModel Class for Your Model"},{"location":"basic/#adding-schemas-to-your-model","text":"To add schema information to the model class, we'll use the pydantic package. The pydantic package allows us to state the schema requirements of the model's input and output programatically as Python classes: from pydantic import BaseModel, Field from pydantic import ValidationError from enum import Enum class ModelInput(BaseModel): sepal_length: float = Field(gt=5.0, lt=8.0, description=\"The length of the sepal of the flower.\") sepal_width: float = Field(gt=2.0, lt=6.0, description=\"The width of the sepal of the flower.\") petal_length: float = Field(gt=1.0, lt=6.8, description=\"The length of the petal of the flower.\") petal_width: float = Field(gt=0.0, lt=3.0, description=\"The width of the petal of the flower.\") class Species(str, Enum): iris_setosa = \"Iris setosa\" iris_versicolor = \"Iris versicolor\" iris_virginica = \"Iris virginica\" class ModelOutput(BaseModel): species: Species = Field(description=\"The predicted species of the flower.\") The ModelInput class inherits from the pydantic BaseModel class and it defines four required fields, all of them floating point numbers. The pydantic package allows for defining upper bounds and lower bounds for the values accepted by each field, and also a description for the field. The ModelOutput is made up of a single fields, which is an enumerated string that contains the predicted species of the flower. Now that we have the ModelInput and ModelOutput schemas defined as pydantic BaseModel classes, we'll add them to the IrisModel class by returning them from the input_schema and output_schema properties: from ml_base.ml_model import MLModel, MLModelSchemaValidationException class IrisModel(MLModel): @property def display_name(self): return \"Iris Model\" @property def qualified_name(self): return \"iris_model\" @property def description(self): return \"A model to predict the species of a flower based on its measurements.\" @property def version(self): return \"1.0.0\" @property def input_schema(self): return ModelInput @property def output_schema(self): return ModelOutput def __init__(self): dir_path = os.path.abspath('') with open(os.path.join(dir_path, \"svc_model.pickle\"), 'rb') as f: self._svm_model = pickle.load(f) def predict(self, data: ModelInput): # creating a numpy array using the fields in the input object X = array([data.sepal_length, data.sepal_width, data.petal_length, data.petal_width]).reshape(1, -1) # making a prediction, at this point its a number y_hat = int(self._svm_model.predict(X)[0]) # converting the prediction from a number to a string targets = [\"Iris setosa\", \"Iris versicolor\", \"Iris virginica\"] species = targets[y_hat] # returning the prediction inside an object return ModelOutput(species=species) Notice that we are also using the pydantic models to validate the input before prediction and to create an object that will be returned from the model's predict() method. If we use the model class now, we'll get this result: model = IrisModel() prediction = model.predict(ModelInput( sepal_length=6.0, sepal_width=2.1, petal_length=1.2, petal_width=1.3)) prediction ModelOutput(species=<Species.iris_virginica: 'Iris virginica'>) By adding input and output schemas to the model, we can automate many other operations later. Also, we can query the model object itself for the schema. The pydantic package is able to create JSON schema from the fields in the input and output schema objects of the model: model = IrisModel() model.input_schema.schema() {'title': 'ModelInput', 'type': 'object', 'properties': {'sepal_length': {'title': 'Sepal Length', 'description': 'The length of the sepal of the flower.', 'exclusiveMinimum': 5.0, 'exclusiveMaximum': 8.0, 'type': 'number'}, 'sepal_width': {'title': 'Sepal Width', 'description': 'The width of the sepal of the flower.', 'exclusiveMinimum': 2.0, 'exclusiveMaximum': 6.0, 'type': 'number'}, 'petal_length': {'title': 'Petal Length', 'description': 'The length of the petal of the flower.', 'exclusiveMinimum': 1.0, 'exclusiveMaximum': 6.8, 'type': 'number'}, 'petal_width': {'title': 'Petal Width', 'description': 'The width of the petal of the flower.', 'exclusiveMinimum': 0.0, 'exclusiveMaximum': 3.0, 'type': 'number'}}, 'required': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']} model.output_schema.schema() {'title': 'ModelOutput', 'type': 'object', 'properties': {'species': {'$ref': '#/definitions/Species'}}, 'required': ['species'], 'definitions': {'Species': {'title': 'Species', 'description': 'An enumeration.', 'enum': ['Iris setosa', 'Iris versicolor', 'Iris virginica'], 'type': 'string'}}} Although it is not required to use the pydantic package to create model schemas, it is recommended. The pydantic package is installed as a dependency of the ml_base package.","title":"Adding Schemas to Your Model"},{"location":"basic/#using-the-modelmanager-class","text":"The ModelManager class is provided to help manage model objects. It is a singleton class that is designed to enable model instances to be instantiated once during the lifecycle of a process and accessed many times: from ml_base.utilities import ModelManager model_manager = ModelManager() Because it is a singleton object, a reference to the same object is returned no matter how many times we instantiate it: print(id(model_manager)) another_model_manager = ModelManager() print(id(another_model_manager)) 4505980208 4505980208 You can add model instances to the ModelManager singleton by asking it to instantiate the model class: model_manager.load_model(\"__main__.IrisModel\") The load_model() method is able to find the MLModel class that we defined above and instantiate it, after that it stores a reference to the instance internally. The ModelManager is also able to save references to model instances that were instantiated in some other way by using the add_model() method: another_iris_model = IrisModel() try: model_manager.add_model(another_iris_model) except ValueError as e: print(e) A model with the same qualified name is already in the ModelManager singleton. In this case, the ModelManager did not save the instance of the IrisModel because we already had an instance of the model. The models are uniquely identified by their qualified name properties. The ModelManager instance can list the models that it contains with the get_models() method, the details of the instance of IrisModel that we just created are returned: model_manager.get_models() [{'display_name': 'Iris Model', 'qualified_name': 'iris_model', 'description': 'A model to predict the species of a flower based on its measurements.', 'version': '1.0.0'}] The ModelManager instance can return the metadata of any of the models. The metadata includes the input and output schemas as well: model_manager.get_model_metadata(\"iris_model\") {'display_name': 'Iris Model', 'qualified_name': 'iris_model', 'description': 'A model to predict the species of a flower based on its measurements.', 'version': '1.0.0', 'input_schema': {'title': 'ModelInput', 'type': 'object', 'properties': {'sepal_length': {'title': 'Sepal Length', 'description': 'The length of the sepal of the flower.', 'exclusiveMinimum': 5.0, 'exclusiveMaximum': 8.0, 'type': 'number'}, 'sepal_width': {'title': 'Sepal Width', 'description': 'The width of the sepal of the flower.', 'exclusiveMinimum': 2.0, 'exclusiveMaximum': 6.0, 'type': 'number'}, 'petal_length': {'title': 'Petal Length', 'description': 'The length of the petal of the flower.', 'exclusiveMinimum': 1.0, 'exclusiveMaximum': 6.8, 'type': 'number'}, 'petal_width': {'title': 'Petal Width', 'description': 'The width of the petal of the flower.', 'exclusiveMinimum': 0.0, 'exclusiveMaximum': 3.0, 'type': 'number'}}, 'required': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']}, 'output_schema': {'title': 'ModelOutput', 'type': 'object', 'properties': {'species': {'$ref': '#/definitions/Species'}}, 'required': ['species'], 'definitions': {'Species': {'title': 'Species', 'description': 'An enumeration.', 'enum': ['Iris setosa', 'Iris versicolor', 'Iris virginica'], 'type': 'string'}}}} The ModelManager can return a reference to the instance of any model that it is holding: iris_model = model_manager.get_model(\"iris_model\") print(iris_model.display_name) Iris Model The instance is identified by the qualified name of the model. Lastly, a model instance can be removed by calling the remove_model() method: model_manager.remove_model(\"iris_model\") model_manager.get_models() [] To clear the ModelManager instance, you can call the clear_instance() method: model_manager.clear_instance() To create a new singleton you have to instantiate the ModelManager again: model_manager = ModelManager()","title":"Using the ModelManager Class"},{"location":"decorator/","text":"MLModelDecorator Example import sys import os sys.path.insert(0, os.path.abspath(os.path.join(\"./\", os.pardir))) Creating a Decorator Decorators are objects that allow us to extend the functionality of other objects at runtime without having to modify the objects that are being decorated. The decorator pattern is a well-known object-oriented design pattern that helps to make code more flexible and reusable. Notice that we are not working with Python decorators, which are used to decorate functions and methods at loading time only (when the function or class is created). The decorators we will work with are run-time decorators since they are applied during the runtime of the program. The objects we want to decorate are MLModel objects, so we'll need an MLModel class to work with. We'll create a simple mocked model class to work with along with the input and output schemas: from ml_base.ml_model import MLModel from pydantic import BaseModel, Field from enum import Enum class ModelInput(BaseModel): sepal_length: float = Field(gt=5.0, lt=8.0) sepal_width: float = Field(gt=2.0, lt=6.0) petal_length: float = Field(gt=1.0, lt=6.8) petal_width: float = Field(gt=0.0, lt=3.0) class Species(str, Enum): iris_setosa = \"Iris setosa\" iris_versicolor = \"Iris versicolor\" iris_virginica = \"Iris virginica\" class ModelOutput(BaseModel): species: Species class IrisModelMock(MLModel): display_name = \"Iris Model\" qualified_name = \"iris_model\" description = \"A model to predict the species of a flower based on its measurements.\" version = \"1.0.0\" input_schema = ModelInput output_schema = ModelOutput def __init__(self): pass def predict(self, data: ModelInput) -> ModelOutput: return ModelOutput(species=\"Iris setosa\") This class mocks the input and output of the IrisModel we used in the previous example. The mocked model will always return a prediction of \"Iris setosa\". We'll instantiate it to make sure that everything works: model = IrisModelMock() prediction = model.predict( ModelInput(sepal_length=5.1, sepal_width=2.2, petal_length=1.2, petal_width=1.3)) prediction ModelOutput(species=<Species.iris_setosa: 'Iris setosa'>) Creating a Simple Decorator Class To create a decorator for MLModel classes, we'll inherit from the MLModelDecorator class: from ml_base import MLModelDecorator from ml_base.ml_model import MLModelException class SimpleDecorator(MLModelDecorator): pass The decorator doesn't do anything but it's still useful because it inherits default behavior from the base class. In order to wrap the model instance with a decorator instance, we instantiate the decorator like this: decorator = SimpleDecorator(model) Now we can make a prediction with the model just like we normally would: prediction = decorator.predict( ModelInput(sepal_length=5.1, sepal_width=2.2, petal_length=1.2, petal_width=1.3)) print(prediction) species=<Species.iris_setosa: 'Iris setosa'> The decorator's default implementation of the predict method does nothing but call the corresponding method in the model instance. The same is true for the other parts of the MLModel API. print(decorator.display_name) print(decorator.qualified_name) print(decorator.description) print(decorator.version) print(decorator.input_schema) print(decorator.output_schema) Iris Model iris_model A model to predict the species of a flower based on its measurements. 1.0.0 <class '__main__.ModelInput'> <class '__main__.ModelOutput'> Creating an MLModelDecorator With Behavior The example above wasn't very useful because it didn't do anything. We'll override the default implementation of the MLModelDecorator base class in order to add some behavior. This decorator executes around the predict() method: class SimplePredictDecorator(MLModelDecorator): def predict(self, data): print(\"Executing before prediction.\") prediction = self._model.predict(data=data) print(\"Executing after prediction.\") return prediction The decorator wraps around the predict() method and does nothing except print a message before and after executing the predict method of the model. We can try it out by wrapping the model instance again: decorator = SimplePredictDecorator(model) Now, we'll call the predict method: prediction = decorator.predict(ModelInput( sepal_length=5.1, sepal_width=2.1, petal_length=1.2, petal_width=1.3)) prediction Executing before prediction. Executing after prediction. ModelOutput(species=<Species.iris_setosa: 'Iris setosa'>) The decorator instance executed before and after the model's predict() method and printed some messages. A More Complex Decorator The MLModelDecorator class is able to \"wrap\" every method and property in the MLModel base class. We'll build a more complex MLModelDecorator to show how this works: class ComplexDecorator(MLModelDecorator): @property def display_name(self) -> str: return self._model.display_name + \" extra\" @property def qualified_name(self) -> str: return self._model.qualified_name + \" extra\" @property def description(self) -> str: return self._model.description + \" extra\" @property def version(self) -> str: return self._model.version + \" extra\" def predict(self, data): print(\"Executing before prediction.\") prediction = self._model.predict(data=data) print(\"Executing after prediction.\") return prediction complex_decorator = ComplexDecorator(model) print(complex_decorator.display_name) print(complex_decorator.qualified_name) print(complex_decorator.description) print(complex_decorator.version) Iris Model extra iris_model extra A model to predict the species of a flower based on its measurements. extra 1.0.0 extra The properties of the MLModel instance were modifyied by adding the word \"extra\" to them, including the input and output schemas, although it would not be a good idea to convert the schema classes to strings in a normal situation. Any other methods, attributes, or properties of an MLModel class that are not part of the MLModel interface are not modified by MLModelDecorator instances that are wrapping them. To show this we'll create an MLModel class with some extra attributes: class IrisModelMockWithExtraAttributes(MLModel): display_name = \"Iris Model\" qualified_name = \"iris_model\" description = \"A model to predict the species of a flower based on its measurements.\" version = \"1.0.0\" input_schema = ModelInput output_schema = ModelOutput def __init__(self): self.extra_attribute = \"extra_attribute\" def predict(self, data: ModelInput) -> ModelOutput: return ModelOutput(species=\"Iris setosa\") @property def extra_property(self): return \"extra_property\" def extra_method(self): return \"extra_method\" model = IrisModelMockWithExtraAttributes() decorator = ComplexDecorator(model) print(decorator.extra_attribute) print(decorator.extra_property) print(decorator.extra_method()) extra_attribute extra_property extra_method The MLModelDecorator class is designed to execute around the public API of the MLModel base class and stay out of the way of any other part of an MLModel instance. When implementing decorators, its important to remember to call the method or return the property of the model instance itself, otherwise the decorator would no longer decorate the model, it would just replace it. Setting the Model After Initialization The MLModelDecorator can also be instantiated without a reference to an MLModel instance to decorate. decorator = ComplexDecorator() decorator ComplexDecorator(None) When we print the decorator, whe model reference inside shows up as \"None\". If we try to execute access the API of the decorator, we'll get an error: try: decorator.version except Exception as e: print(e) 'NoneType' object has no attribute 'version' To set the model instances after initialization, we can use the set_model() method. decorator.set_model(model) decorator ComplexDecorator(IrisModelMockWithExtraAttributes) Accessing the decorator now accesses the model as show above: decorator.version '1.0.0 extra' Displaying the Decorator Once a model instance has been decorated, we can see that it is decorating when we print it: decorator ComplexDecorator(IrisModelMockWithExtraAttributes) The ComplexDecorator is wrapping an instance of MLModelMock. If we add another decorator, we can see it is decorated again: decorator = SimplePredictDecorator(decorator) decorator SimplePredictDecorator(ComplexDecorator(IrisModelMockWithExtraAttributes)) Decorators can decorate other instances of decorators because they have the same API as MLModel. Creating an Exception Handler Decorator To show a real example of what a decorator can do, we'll create a decorator that handles exceptions raised in the predict() method and logs them. import logging logger = logging.getLogger(__name__) class ExceptionLoggerDecorator(MLModelDecorator): def predict(self, data): try: return self._model.predict(data=data) except Exception as e: logger.exception(\"Exception in the predict() method of {}.\".format(str(self._model))) We'll need to raise an exception in the model class' predict() method in order to try this out, so we'll redefine the IrisModelMock class to raise an exception: class IrisModelMock(MLModel): display_name = \"Iris Model\" qualified_name = \"iris_model\" description = \"A model to predict the species of a flower based on its measurements.\" version = \"1.0.0\" input_schema = ModelInput output_schema = ModelOutput def __init__(self): pass def predict(self, data): raise Exception(\"Exception!\") Now all we need is to instantiate the MLModel class and the decorator to try it out: model = IrisModelMock() decorator = ExceptionLoggerDecorator(model) # making a failing prediction prediction = decorator.predict(ModelInput( sepal_length=5.1, sepal_width=2.1, petal_length=1.2, petal_width=1.3)) Exception in the predict() method of IrisModelMock. Traceback (most recent call last): File \"<ipython-input-21-ea4dab4c8b70>\", line 11, in predict return self._model.predict(data=data) File \"<ipython-input-22-79739fa901dd>\", line 13, in predict raise Exception(\"Exception!\") Exception: Exception! The exception was caught by the decorator and logged. Configurable MLModel Decorator Next, we'll build an MLModelDecorator that can be configured. class AddStringDecorator(MLModelDecorator): def __init__(self, model: MLModel, extra_name: str) -> None: super().__init__(model, extra_name=extra_name) @property def display_name(self) -> str: return self._model.display_name + self._configuration[\"extra_name\"] The __init__() method receives the normal \"model\" parameter and passes it to the super class. It also receives a parameter called \"extra_name\" which is also passed to the super class as a keyword argument. Each configuration items should be passed to the super class in this way. The decorator adds a string to the display_name property of the model object: model = IrisModelMock() decorator = AddStringDecorator(model, extra_name=\" extra name\") Now when we access the properties, we'll get the string we configured added to the end: print(decorator.display_name) Iris Model extra name Once the configuration has been passed to the MLModelDecorator super class as a keyword argument, it is saved in the \"_configuration\" attribute and can be accessed by the methods in the decorator class. This also means that the \"_configuration\" and \"_model\" names are reserved within MLModelDecorator classes because they are being used by the base class. You can also set the values in the \"_configuration\" and \"_model\" attributes of the decorator: decorator._configuration[\"asdf\"] = \"asdf\" decorator._configuration {'extra_name': ' extra name', 'asdf': 'asdf'} Adding the Decorated Model to the ModelManager Adding a decorated model to the ModelManager singleton is simple. First we'll create a decorated model: model = IrisModelMock() decorated_model = SimpleDecorator(model) Next, we'll create the ModelManager: from ml_base.utilities import ModelManager model_manager = ModelManager() Finally, we'll add the decorated model as we normally would: model_manager.add_model(decorated_model) model_manager.get_model_metadata(\"iris_model\") {'display_name': 'Iris Model', 'qualified_name': 'iris_model', 'description': 'A model to predict the species of a flower based on its measurements.', 'version': '1.0.0', 'input_schema': {'title': 'ModelInput', 'type': 'object', 'properties': {'sepal_length': {'title': 'Sepal Length', 'exclusiveMinimum': 5.0, 'exclusiveMaximum': 8.0, 'type': 'number'}, 'sepal_width': {'title': 'Sepal Width', 'exclusiveMinimum': 2.0, 'exclusiveMaximum': 6.0, 'type': 'number'}, 'petal_length': {'title': 'Petal Length', 'exclusiveMinimum': 1.0, 'exclusiveMaximum': 6.8, 'type': 'number'}, 'petal_width': {'title': 'Petal Width', 'exclusiveMinimum': 0.0, 'exclusiveMaximum': 3.0, 'type': 'number'}}, 'required': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']}, 'output_schema': {'title': 'ModelOutput', 'type': 'object', 'properties': {'species': {'$ref': '#/definitions/Species'}}, 'required': ['species'], 'definitions': {'Species': {'title': 'Species', 'description': 'An enumeration.', 'enum': ['Iris setosa', 'Iris versicolor', 'Iris virginica'], 'type': 'string'}}}} The ModelManager is able to work with the decorated model object because it has the same interface as MLModel. model_manager.clear_instance() Adding a Decorator to a Model in the ModelManager The ModelManager also has support for decorating models that are already held inside by using the add_decorator() method: from ml_base.utilities import ModelManager model_manager = ModelManager() model = IrisModelMock() model_manager.add_model(model) print(model_manager.get_models()) [{'display_name': 'Iris Model', 'qualified_name': 'iris_model', 'description': 'A model to predict the species of a flower based on its measurements.', 'version': '1.0.0'}] decorator = SimpleDecorator() model_manager.add_decorator(\"iris_model\", decorator) When we access the model instance, we can see that it is now decorated: model = model_manager.get_model(\"iris_model\") model SimpleDecorator(IrisModelMock)","title":"Decorator Examples"},{"location":"decorator/#mlmodeldecorator-example","text":"import sys import os sys.path.insert(0, os.path.abspath(os.path.join(\"./\", os.pardir)))","title":"MLModelDecorator Example"},{"location":"decorator/#creating-a-decorator","text":"Decorators are objects that allow us to extend the functionality of other objects at runtime without having to modify the objects that are being decorated. The decorator pattern is a well-known object-oriented design pattern that helps to make code more flexible and reusable. Notice that we are not working with Python decorators, which are used to decorate functions and methods at loading time only (when the function or class is created). The decorators we will work with are run-time decorators since they are applied during the runtime of the program. The objects we want to decorate are MLModel objects, so we'll need an MLModel class to work with. We'll create a simple mocked model class to work with along with the input and output schemas: from ml_base.ml_model import MLModel from pydantic import BaseModel, Field from enum import Enum class ModelInput(BaseModel): sepal_length: float = Field(gt=5.0, lt=8.0) sepal_width: float = Field(gt=2.0, lt=6.0) petal_length: float = Field(gt=1.0, lt=6.8) petal_width: float = Field(gt=0.0, lt=3.0) class Species(str, Enum): iris_setosa = \"Iris setosa\" iris_versicolor = \"Iris versicolor\" iris_virginica = \"Iris virginica\" class ModelOutput(BaseModel): species: Species class IrisModelMock(MLModel): display_name = \"Iris Model\" qualified_name = \"iris_model\" description = \"A model to predict the species of a flower based on its measurements.\" version = \"1.0.0\" input_schema = ModelInput output_schema = ModelOutput def __init__(self): pass def predict(self, data: ModelInput) -> ModelOutput: return ModelOutput(species=\"Iris setosa\") This class mocks the input and output of the IrisModel we used in the previous example. The mocked model will always return a prediction of \"Iris setosa\". We'll instantiate it to make sure that everything works: model = IrisModelMock() prediction = model.predict( ModelInput(sepal_length=5.1, sepal_width=2.2, petal_length=1.2, petal_width=1.3)) prediction ModelOutput(species=<Species.iris_setosa: 'Iris setosa'>)","title":"Creating a Decorator"},{"location":"decorator/#creating-a-simple-decorator-class","text":"To create a decorator for MLModel classes, we'll inherit from the MLModelDecorator class: from ml_base import MLModelDecorator from ml_base.ml_model import MLModelException class SimpleDecorator(MLModelDecorator): pass The decorator doesn't do anything but it's still useful because it inherits default behavior from the base class. In order to wrap the model instance with a decorator instance, we instantiate the decorator like this: decorator = SimpleDecorator(model) Now we can make a prediction with the model just like we normally would: prediction = decorator.predict( ModelInput(sepal_length=5.1, sepal_width=2.2, petal_length=1.2, petal_width=1.3)) print(prediction) species=<Species.iris_setosa: 'Iris setosa'> The decorator's default implementation of the predict method does nothing but call the corresponding method in the model instance. The same is true for the other parts of the MLModel API. print(decorator.display_name) print(decorator.qualified_name) print(decorator.description) print(decorator.version) print(decorator.input_schema) print(decorator.output_schema) Iris Model iris_model A model to predict the species of a flower based on its measurements. 1.0.0 <class '__main__.ModelInput'> <class '__main__.ModelOutput'>","title":"Creating a Simple Decorator Class"},{"location":"decorator/#creating-an-mlmodeldecorator-with-behavior","text":"The example above wasn't very useful because it didn't do anything. We'll override the default implementation of the MLModelDecorator base class in order to add some behavior. This decorator executes around the predict() method: class SimplePredictDecorator(MLModelDecorator): def predict(self, data): print(\"Executing before prediction.\") prediction = self._model.predict(data=data) print(\"Executing after prediction.\") return prediction The decorator wraps around the predict() method and does nothing except print a message before and after executing the predict method of the model. We can try it out by wrapping the model instance again: decorator = SimplePredictDecorator(model) Now, we'll call the predict method: prediction = decorator.predict(ModelInput( sepal_length=5.1, sepal_width=2.1, petal_length=1.2, petal_width=1.3)) prediction Executing before prediction. Executing after prediction. ModelOutput(species=<Species.iris_setosa: 'Iris setosa'>) The decorator instance executed before and after the model's predict() method and printed some messages.","title":"Creating an MLModelDecorator With Behavior"},{"location":"decorator/#a-more-complex-decorator","text":"The MLModelDecorator class is able to \"wrap\" every method and property in the MLModel base class. We'll build a more complex MLModelDecorator to show how this works: class ComplexDecorator(MLModelDecorator): @property def display_name(self) -> str: return self._model.display_name + \" extra\" @property def qualified_name(self) -> str: return self._model.qualified_name + \" extra\" @property def description(self) -> str: return self._model.description + \" extra\" @property def version(self) -> str: return self._model.version + \" extra\" def predict(self, data): print(\"Executing before prediction.\") prediction = self._model.predict(data=data) print(\"Executing after prediction.\") return prediction complex_decorator = ComplexDecorator(model) print(complex_decorator.display_name) print(complex_decorator.qualified_name) print(complex_decorator.description) print(complex_decorator.version) Iris Model extra iris_model extra A model to predict the species of a flower based on its measurements. extra 1.0.0 extra The properties of the MLModel instance were modifyied by adding the word \"extra\" to them, including the input and output schemas, although it would not be a good idea to convert the schema classes to strings in a normal situation. Any other methods, attributes, or properties of an MLModel class that are not part of the MLModel interface are not modified by MLModelDecorator instances that are wrapping them. To show this we'll create an MLModel class with some extra attributes: class IrisModelMockWithExtraAttributes(MLModel): display_name = \"Iris Model\" qualified_name = \"iris_model\" description = \"A model to predict the species of a flower based on its measurements.\" version = \"1.0.0\" input_schema = ModelInput output_schema = ModelOutput def __init__(self): self.extra_attribute = \"extra_attribute\" def predict(self, data: ModelInput) -> ModelOutput: return ModelOutput(species=\"Iris setosa\") @property def extra_property(self): return \"extra_property\" def extra_method(self): return \"extra_method\" model = IrisModelMockWithExtraAttributes() decorator = ComplexDecorator(model) print(decorator.extra_attribute) print(decorator.extra_property) print(decorator.extra_method()) extra_attribute extra_property extra_method The MLModelDecorator class is designed to execute around the public API of the MLModel base class and stay out of the way of any other part of an MLModel instance. When implementing decorators, its important to remember to call the method or return the property of the model instance itself, otherwise the decorator would no longer decorate the model, it would just replace it.","title":"A More Complex Decorator"},{"location":"decorator/#setting-the-model-after-initialization","text":"The MLModelDecorator can also be instantiated without a reference to an MLModel instance to decorate. decorator = ComplexDecorator() decorator ComplexDecorator(None) When we print the decorator, whe model reference inside shows up as \"None\". If we try to execute access the API of the decorator, we'll get an error: try: decorator.version except Exception as e: print(e) 'NoneType' object has no attribute 'version' To set the model instances after initialization, we can use the set_model() method. decorator.set_model(model) decorator ComplexDecorator(IrisModelMockWithExtraAttributes) Accessing the decorator now accesses the model as show above: decorator.version '1.0.0 extra'","title":"Setting the Model After Initialization"},{"location":"decorator/#displaying-the-decorator","text":"Once a model instance has been decorated, we can see that it is decorating when we print it: decorator ComplexDecorator(IrisModelMockWithExtraAttributes) The ComplexDecorator is wrapping an instance of MLModelMock. If we add another decorator, we can see it is decorated again: decorator = SimplePredictDecorator(decorator) decorator SimplePredictDecorator(ComplexDecorator(IrisModelMockWithExtraAttributes)) Decorators can decorate other instances of decorators because they have the same API as MLModel.","title":"Displaying the Decorator"},{"location":"decorator/#creating-an-exception-handler-decorator","text":"To show a real example of what a decorator can do, we'll create a decorator that handles exceptions raised in the predict() method and logs them. import logging logger = logging.getLogger(__name__) class ExceptionLoggerDecorator(MLModelDecorator): def predict(self, data): try: return self._model.predict(data=data) except Exception as e: logger.exception(\"Exception in the predict() method of {}.\".format(str(self._model))) We'll need to raise an exception in the model class' predict() method in order to try this out, so we'll redefine the IrisModelMock class to raise an exception: class IrisModelMock(MLModel): display_name = \"Iris Model\" qualified_name = \"iris_model\" description = \"A model to predict the species of a flower based on its measurements.\" version = \"1.0.0\" input_schema = ModelInput output_schema = ModelOutput def __init__(self): pass def predict(self, data): raise Exception(\"Exception!\") Now all we need is to instantiate the MLModel class and the decorator to try it out: model = IrisModelMock() decorator = ExceptionLoggerDecorator(model) # making a failing prediction prediction = decorator.predict(ModelInput( sepal_length=5.1, sepal_width=2.1, petal_length=1.2, petal_width=1.3)) Exception in the predict() method of IrisModelMock. Traceback (most recent call last): File \"<ipython-input-21-ea4dab4c8b70>\", line 11, in predict return self._model.predict(data=data) File \"<ipython-input-22-79739fa901dd>\", line 13, in predict raise Exception(\"Exception!\") Exception: Exception! The exception was caught by the decorator and logged.","title":"Creating an Exception Handler Decorator"},{"location":"decorator/#configurable-mlmodel-decorator","text":"Next, we'll build an MLModelDecorator that can be configured. class AddStringDecorator(MLModelDecorator): def __init__(self, model: MLModel, extra_name: str) -> None: super().__init__(model, extra_name=extra_name) @property def display_name(self) -> str: return self._model.display_name + self._configuration[\"extra_name\"] The __init__() method receives the normal \"model\" parameter and passes it to the super class. It also receives a parameter called \"extra_name\" which is also passed to the super class as a keyword argument. Each configuration items should be passed to the super class in this way. The decorator adds a string to the display_name property of the model object: model = IrisModelMock() decorator = AddStringDecorator(model, extra_name=\" extra name\") Now when we access the properties, we'll get the string we configured added to the end: print(decorator.display_name) Iris Model extra name Once the configuration has been passed to the MLModelDecorator super class as a keyword argument, it is saved in the \"_configuration\" attribute and can be accessed by the methods in the decorator class. This also means that the \"_configuration\" and \"_model\" names are reserved within MLModelDecorator classes because they are being used by the base class. You can also set the values in the \"_configuration\" and \"_model\" attributes of the decorator: decorator._configuration[\"asdf\"] = \"asdf\" decorator._configuration {'extra_name': ' extra name', 'asdf': 'asdf'}","title":"Configurable MLModel Decorator"},{"location":"decorator/#adding-the-decorated-model-to-the-modelmanager","text":"Adding a decorated model to the ModelManager singleton is simple. First we'll create a decorated model: model = IrisModelMock() decorated_model = SimpleDecorator(model) Next, we'll create the ModelManager: from ml_base.utilities import ModelManager model_manager = ModelManager() Finally, we'll add the decorated model as we normally would: model_manager.add_model(decorated_model) model_manager.get_model_metadata(\"iris_model\") {'display_name': 'Iris Model', 'qualified_name': 'iris_model', 'description': 'A model to predict the species of a flower based on its measurements.', 'version': '1.0.0', 'input_schema': {'title': 'ModelInput', 'type': 'object', 'properties': {'sepal_length': {'title': 'Sepal Length', 'exclusiveMinimum': 5.0, 'exclusiveMaximum': 8.0, 'type': 'number'}, 'sepal_width': {'title': 'Sepal Width', 'exclusiveMinimum': 2.0, 'exclusiveMaximum': 6.0, 'type': 'number'}, 'petal_length': {'title': 'Petal Length', 'exclusiveMinimum': 1.0, 'exclusiveMaximum': 6.8, 'type': 'number'}, 'petal_width': {'title': 'Petal Width', 'exclusiveMinimum': 0.0, 'exclusiveMaximum': 3.0, 'type': 'number'}}, 'required': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']}, 'output_schema': {'title': 'ModelOutput', 'type': 'object', 'properties': {'species': {'$ref': '#/definitions/Species'}}, 'required': ['species'], 'definitions': {'Species': {'title': 'Species', 'description': 'An enumeration.', 'enum': ['Iris setosa', 'Iris versicolor', 'Iris virginica'], 'type': 'string'}}}} The ModelManager is able to work with the decorated model object because it has the same interface as MLModel. model_manager.clear_instance()","title":"Adding the Decorated Model to the ModelManager"},{"location":"decorator/#adding-a-decorator-to-a-model-in-the-modelmanager","text":"The ModelManager also has support for decorating models that are already held inside by using the add_decorator() method: from ml_base.utilities import ModelManager model_manager = ModelManager() model = IrisModelMock() model_manager.add_model(model) print(model_manager.get_models()) [{'display_name': 'Iris Model', 'qualified_name': 'iris_model', 'description': 'A model to predict the species of a flower based on its measurements.', 'version': '1.0.0'}] decorator = SimpleDecorator() model_manager.add_decorator(\"iris_model\", decorator) When we access the model instance, we can see that it is now decorated: model = model_manager.get_model(\"iris_model\") model SimpleDecorator(IrisModelMock)","title":"Adding a Decorator to a Model in the ModelManager"}]}