{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the ML Base Package Documentation","text":"<p>The ml_base package is useful for deploying machine learning models.</p>"},{"location":"#introduction","title":"Introduction","text":"<p>The ml_base package defines a common set of base classes that are useful for working with machine learning model prediction code. The base classes define a set of interfaces that help to write ML code that is reusable and testable.</p> <p>The core of the ml_base package is the MLModel class which defines a simple interface for doing machine learning model prediction. The MLModel base class allows the developer of the model to return this information to the user of the model in a standardized way:</p> <ul> <li>Model Qualified Name, a unique identifier for the model</li> <li>Model Display Name, a friendly name for the model used in user interfaces</li> <li>Model Description, a description for the model</li> <li>Model Version, semantic version of the model codebase</li> <li>Model Input Schema, an object that describes the model's input data</li> <li>Model Output Schema, an object that describes the model's output schema</li> </ul> <p>The package also includes a ModelManager class that is able to instantiate and manage models that are created using the MLModel base class.</p> <p>The package also provides a way to create decorators that work with MLModel instances to enable more complex behavior  for the decorated model. Examples for MLModel decorators can be found in the examples section of this site. </p>"},{"location":"#faq","title":"FAQ","text":""},{"location":"#why-bother-with-base-classes-and-interfaces-isnt-it-just-extra-work","title":"Why bother with base classes and interfaces? Isn't it just extra work?","text":"<p>Interface-driven software development can be very helpful when building complex software systems. By using the MLModel base class to deliver the prediction functionality, developing software that makes use of the machine learning model is greatly simplified, and the model is much more accessible and easier to use. Developing the prediction functionality of your ML model around the MLModel base class provides a simple \"meeting point\" between your model and anyone that wants to use it, the user doesn't need to worry about the implementation of the model and you don't need to worry about the use cases that your model will be used in.</p>"},{"location":"#why-not-just-deliver-a-serialized-model-object-to-the-software-engineer","title":"Why not just deliver a serialized model object to the software engineer?","text":"<p>Having a class that wraps around your model object provides a great place to do things that make your model easier to use. For example:</p> <ul> <li>Deserialize model parameters from disk so that using the model is a easy as instantiating a class and calling      predict()</li> <li>Validate inputs before sending them to the model.</li> <li>Modify predictions before sending them back to the calling code.</li> <li>Return metadata about your model.</li> <li>Convert model inputs from a developer-friendly data structure (dictionaries and lists) to a model-friendly data      structure (dataframes).</li> <li>Convert model outputs from a dataframe to a dictionary or list.</li> </ul>"},{"location":"#so-what-do-i-have-to-do-to-use-the-base-classes","title":"So what do I have to do to use the base classes?","text":"<p>Create a wrapper class around your model that inherits from the MLModel base class and implement the required methods. You can follow the example implementation available in the documentation.</p>"},{"location":"api/","title":"API documentation","text":""},{"location":"api/#base-classes","title":"Base Classes","text":"<p>Base class for building ML models that are easy to deploy and integrate.</p> <p>Base class for building decorators for MLModel objects.</p>"},{"location":"api/#ml_base.ml_model.MLModel","title":"<code>MLModel</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Base class for ML model prediction code.</p> Source code in <code>ml_base/ml_model.py</code> <pre><code>class MLModel(ABC):\n\"\"\"Base class for ML model prediction code.\"\"\"\n\n    def __repr__(self) -&gt; str:\n\"\"\"Return a string representing the model object.\"\"\"\n        return self.__class__.__name__\n\n    @property\n    @abstractmethod\n    def display_name(self) -&gt; str:\n\"\"\"Abstract property that returns a display name for the model.\n\n        Returns:\n            str: The display name of the model.\n\n        !!! note\n            This is a name for the model that looks good in user interfaces.\n\n        \"\"\"\n        raise NotImplementedError()  # pragma: no cover\n\n    @property\n    @abstractmethod\n    def qualified_name(self) -&gt; str:\n\"\"\"Abstract property that returns the qualified name of the model.\n\n        Returns:\n            str: The qualified name of the model.\n\n        !!! warning\n            A qualified name is an unambiguous identifier for the model.\n\n        \"\"\"\n        raise NotImplementedError()  # pragma: no cover\n\n    @property\n    @abstractmethod\n    def description(self) -&gt; str:\n\"\"\"Abstract property that returns a description of the model.\n\n        Returns:\n            str: The description of the model.\n\n        \"\"\"\n        raise NotImplementedError()  # pragma: no cover\n\n    @property\n    @abstractmethod\n    def version(self) -&gt; str:\n\"\"\"Abstract property that returns the model's version as a string.\n\n        Returns:\n            str: The version of the model.\n\n        \"\"\"\n        raise NotImplementedError()  # pragma: no cover\n\n    @property\n    @abstractmethod\n    def input_schema(self) -&gt; BaseModel:\n\"\"\"Property that returns the schema that is accepted by the predict() method.\n\n        Returns:\n            pydantic.BaseModel: The input schema of the model.\n\n        !!! note\n            This property must return a subtype of pydantic.BaseModel.\n\n        \"\"\"\n        raise NotImplementedError()  # pragma: no cover\n\n    @property\n    @abstractmethod\n    def output_schema(self) -&gt; BaseModel:\n\"\"\"Property returns the schema that is returned by the predict() method.\n\n        Returns:\n            pydantic.BaseModel: The output schema of the model.\n\n        !!! note\n            This property must return a subtype of pydantic.BaseModel.\n\n        \"\"\"\n        raise NotImplementedError()  # pragma: no cover\n\n    @abstractmethod\n    def __init__(self) -&gt; None:\n\"\"\"Create an MLModel instance by adding any deserialization and initialization code for the model.\"\"\"\n        raise NotImplementedError()  # pragma: no cover\n\n    @abstractmethod\n    def predict(self, data: BaseModel) -&gt; BaseModel:\n\"\"\"Prediction with the model.\n\n        Args:\n            data: data used by the model for making a prediction\n\n        Returns:\n            object: can be any python type\n\n        \"\"\"\n        raise NotImplementedError()  # pragma: no cover\n</code></pre>"},{"location":"api/#ml_base.ml_model.MLModel.description","title":"<code>description: str</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Abstract property that returns a description of the model.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The description of the model.</p>"},{"location":"api/#ml_base.ml_model.MLModel.display_name","title":"<code>display_name: str</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Abstract property that returns a display name for the model.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The display name of the model.</p> <p>Note</p> <p>This is a name for the model that looks good in user interfaces.</p>"},{"location":"api/#ml_base.ml_model.MLModel.input_schema","title":"<code>input_schema: BaseModel</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Property that returns the schema that is accepted by the predict() method.</p> <p>Returns:</p> Type Description <code>BaseModel</code> <p>pydantic.BaseModel: The input schema of the model.</p> <p>Note</p> <p>This property must return a subtype of pydantic.BaseModel.</p>"},{"location":"api/#ml_base.ml_model.MLModel.output_schema","title":"<code>output_schema: BaseModel</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Property returns the schema that is returned by the predict() method.</p> <p>Returns:</p> Type Description <code>BaseModel</code> <p>pydantic.BaseModel: The output schema of the model.</p> <p>Note</p> <p>This property must return a subtype of pydantic.BaseModel.</p>"},{"location":"api/#ml_base.ml_model.MLModel.qualified_name","title":"<code>qualified_name: str</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Abstract property that returns the qualified name of the model.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The qualified name of the model.</p> <p>Warning</p> <p>A qualified name is an unambiguous identifier for the model.</p>"},{"location":"api/#ml_base.ml_model.MLModel.version","title":"<code>version: str</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Abstract property that returns the model's version as a string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The version of the model.</p>"},{"location":"api/#ml_base.ml_model.MLModel.__init__","title":"<code>__init__()</code>  <code>abstractmethod</code>","text":"<p>Create an MLModel instance by adding any deserialization and initialization code for the model.</p> Source code in <code>ml_base/ml_model.py</code> <pre><code>@abstractmethod\ndef __init__(self) -&gt; None:\n\"\"\"Create an MLModel instance by adding any deserialization and initialization code for the model.\"\"\"\n    raise NotImplementedError()  # pragma: no cover\n</code></pre>"},{"location":"api/#ml_base.ml_model.MLModel.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representing the model object.</p> Source code in <code>ml_base/ml_model.py</code> <pre><code>def __repr__(self) -&gt; str:\n\"\"\"Return a string representing the model object.\"\"\"\n    return self.__class__.__name__\n</code></pre>"},{"location":"api/#ml_base.ml_model.MLModel.predict","title":"<code>predict(data)</code>  <code>abstractmethod</code>","text":"<p>Prediction with the model.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>BaseModel</code> <p>data used by the model for making a prediction</p> required <p>Returns:</p> Name Type Description <code>object</code> <code>BaseModel</code> <p>can be any python type</p> Source code in <code>ml_base/ml_model.py</code> <pre><code>@abstractmethod\ndef predict(self, data: BaseModel) -&gt; BaseModel:\n\"\"\"Prediction with the model.\n\n    Args:\n        data: data used by the model for making a prediction\n\n    Returns:\n        object: can be any python type\n\n    \"\"\"\n    raise NotImplementedError()  # pragma: no cover\n</code></pre>"},{"location":"api/#ml_base.ml_model.MLModelException","title":"<code>MLModelException</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Exception base class used to raise exceptions within MLModel derived classes.</p> Source code in <code>ml_base/ml_model.py</code> <pre><code>class MLModelException(Exception):\n\"\"\"Exception base class used to raise exceptions within MLModel derived classes.\"\"\"\n\n    def __init__(self, *args: tuple) -&gt; None:\n\"\"\"Initialize MLModelException instance.\"\"\"\n        Exception.__init__(self, *args)\n</code></pre>"},{"location":"api/#ml_base.ml_model.MLModelException.__init__","title":"<code>__init__(*args)</code>","text":"<p>Initialize MLModelException instance.</p> Source code in <code>ml_base/ml_model.py</code> <pre><code>def __init__(self, *args: tuple) -&gt; None:\n\"\"\"Initialize MLModelException instance.\"\"\"\n    Exception.__init__(self, *args)\n</code></pre>"},{"location":"api/#ml_base.ml_model.MLModelSchemaValidationException","title":"<code>MLModelSchemaValidationException</code>","text":"<p>         Bases: <code>MLModelException</code></p> <p>Exception type used to raise schema validation exceptions within MLModel derived classes.</p> Source code in <code>ml_base/ml_model.py</code> <pre><code>class MLModelSchemaValidationException(MLModelException):\n\"\"\"Exception type used to raise schema validation exceptions within MLModel derived classes.\"\"\"\n\n    def __init__(self, *args: tuple) -&gt; None:\n\"\"\"Initialize MLModelSchemaValidationException instance.\"\"\"\n        MLModelException.__init__(self, *args)\n</code></pre>"},{"location":"api/#ml_base.ml_model.MLModelSchemaValidationException.__init__","title":"<code>__init__(*args)</code>","text":"<p>Initialize MLModelSchemaValidationException instance.</p> Source code in <code>ml_base/ml_model.py</code> <pre><code>def __init__(self, *args: tuple) -&gt; None:\n\"\"\"Initialize MLModelSchemaValidationException instance.\"\"\"\n    MLModelException.__init__(self, *args)\n</code></pre>"},{"location":"api/#ml_base.decorator.MLModelDecorator","title":"<code>MLModelDecorator</code>","text":"<p>         Bases: <code>MLModel</code></p> <p>Base class for ML model decorator code.</p> <p>Note</p> <p>The default behavior of the MLModelDecorator base class is to do nothing and to forward the method call to the model that is is wrapping. Any subtypes of MLModelDecorator that would like to add on to the behavior of the model needs to override the default implementations in the MLModelDecorator base class.</p> Source code in <code>ml_base/decorator.py</code> <pre><code>class MLModelDecorator(MLModel):\n\"\"\"Base class for ML model decorator code.\n\n    !!! note\n        The default behavior of the MLModelDecorator base class is to do nothing and to forward the method call to\n        the model that is is wrapping. Any subtypes of MLModelDecorator that would like to add on to the behavior\n        of the model needs to override the default implementations in the MLModelDecorator base class.\n\n    \"\"\"\n\n    _decorator_attributes = [\"_model\", \"_configuration\"]\n\n    def __init__(self, model: Optional[MLModel] = None, **kwargs: dict) -&gt; None:\n\"\"\"Initialize MLModelDecorator instance.\n\n        !!! note\n            The MLModel parameter is optional and does not need to be provided at initialization of the decorator\n            instance.\n\n        !!! note\n            This method receives the model instance and stores the reference.\n\n        \"\"\"\n        if model is not None and not isinstance(model, MLModel):\n            raise ValueError(\"Only objects of type MLModel can be wrapped with MLModelDecorator instances.\")\n\n        self.__dict__[\"_model\"] = model\n        self.__dict__[\"_configuration\"] = kwargs\n\n    def __repr__(self) -&gt; str:\n\"\"\"Return a string describing the decorator and the model that it is decorating.\"\"\"\n        return \"{}({})\".format(self.__class__.__name__, str(self.__dict__[\"_model\"]))\n\n    def set_model(self, model: MLModel) -&gt; \"MLModelDecorator\":\n\"\"\"Set a model in the decorator instance.\"\"\"\n        if not isinstance(model, MLModel):\n            raise ValueError(\"Only objects of type MLModel can be wrapped with MLModelDecorator instances.\")\n\n        self.__dict__[\"_model\"] = model\n        return self\n\n    def __getattr__(self, name: str) -&gt; Any:\n\"\"\"Get an attribute.\"\"\"\n        if name in MLModelDecorator._decorator_attributes:\n            return self.__dict__[name]\n        else:\n            return getattr(self.__dict__[\"_model\"], name)\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n\"\"\"Set an attribute.\"\"\"\n        if name in MLModelDecorator._decorator_attributes:\n            setattr(self, name, value)\n        else:\n            setattr(self.__dict__[\"_model\"], name, value)\n\n    def __delattr__(self, name: str) -&gt; None:\n\"\"\"Delete an attribute.\"\"\"\n        delattr(self.__dict__[\"_model\"], name)\n\n    @property\n    def display_name(self) -&gt; str:\n\"\"\"Property that returns a display name for the model.\n\n        !!! note\n            Unless this method is overridden, the implementation just returns the display_name property of the\n            model that is being decorated.\n\n        \"\"\"\n        return getattr(self, \"_model\").display_name\n\n    @property\n    def qualified_name(self) -&gt; str:\n\"\"\"Property that returns the qualified name of the model.\n\n        !!! note\n            Unless this method is overridden, the implementation just returns the qualified_name property of the\n            model that is being decorated.\n\n        \"\"\"\n        return getattr(self, \"_model\").qualified_name\n\n    @property\n    def description(self) -&gt; str:\n\"\"\"Property that returns a description of the model.\n\n        !!! note\n            Unless this method is overridden, the implementation just returns the description property of the\n            model that is being decorated.\n\n        \"\"\"\n        return getattr(self, \"_model\").description\n\n    @property\n    def version(self) -&gt; str:\n\"\"\"Property that returns the model's version as a string.\n\n        !!! note\n            Unless this method is overridden, the implementation just returns the version property of the\n            model that is being decorated.\n\n\n        \"\"\"\n        return getattr(self, \"_model\").version\n\n    @property\n    def input_schema(self) -&gt; BaseModel:\n\"\"\"Property that returns the schema that is accepted by the predict() method.\n\n        !!! note\n            Unless this method is overridden, the implementation just returns the input_schema property of the\n            model that is being decorated.\n\n        \"\"\"\n        return getattr(self, \"_model\").input_schema\n\n    @property\n    def output_schema(self) -&gt; BaseModel:\n\"\"\"Property returns the schema that is returned by the predict() method.\n\n        !!! note\n            Unless this method is overridden, the implementation just returns the output_schema property of the\n            model that is being decorated.\n\n        \"\"\"\n        return getattr(self, \"_model\").output_schema\n\n    def predict(self, data: BaseModel) -&gt; BaseModel:\n\"\"\"Predict with the model.\n\n        Params:\n            data: Data used by the model for making a prediction.\n\n        Returns:\n            python object -- can be any python type\n\n        !!! note\n            Unless this method is overridden, the implementation just calls the predict method of the\n            model that is being decorated and returns the result.\n\n        \"\"\"\n        return getattr(self, \"_model\").predict(data=data)\n</code></pre>"},{"location":"api/#ml_base.decorator.MLModelDecorator.description","title":"<code>description: str</code>  <code>property</code>","text":"<p>Property that returns a description of the model.</p> <p>Note</p> <p>Unless this method is overridden, the implementation just returns the description property of the model that is being decorated.</p>"},{"location":"api/#ml_base.decorator.MLModelDecorator.display_name","title":"<code>display_name: str</code>  <code>property</code>","text":"<p>Property that returns a display name for the model.</p> <p>Note</p> <p>Unless this method is overridden, the implementation just returns the display_name property of the model that is being decorated.</p>"},{"location":"api/#ml_base.decorator.MLModelDecorator.input_schema","title":"<code>input_schema: BaseModel</code>  <code>property</code>","text":"<p>Property that returns the schema that is accepted by the predict() method.</p> <p>Note</p> <p>Unless this method is overridden, the implementation just returns the input_schema property of the model that is being decorated.</p>"},{"location":"api/#ml_base.decorator.MLModelDecorator.output_schema","title":"<code>output_schema: BaseModel</code>  <code>property</code>","text":"<p>Property returns the schema that is returned by the predict() method.</p> <p>Note</p> <p>Unless this method is overridden, the implementation just returns the output_schema property of the model that is being decorated.</p>"},{"location":"api/#ml_base.decorator.MLModelDecorator.qualified_name","title":"<code>qualified_name: str</code>  <code>property</code>","text":"<p>Property that returns the qualified name of the model.</p> <p>Note</p> <p>Unless this method is overridden, the implementation just returns the qualified_name property of the model that is being decorated.</p>"},{"location":"api/#ml_base.decorator.MLModelDecorator.version","title":"<code>version: str</code>  <code>property</code>","text":"<p>Property that returns the model's version as a string.</p> <p>Note</p> <p>Unless this method is overridden, the implementation just returns the version property of the model that is being decorated.</p>"},{"location":"api/#ml_base.decorator.MLModelDecorator.__delattr__","title":"<code>__delattr__(name)</code>","text":"<p>Delete an attribute.</p> Source code in <code>ml_base/decorator.py</code> <pre><code>def __delattr__(self, name: str) -&gt; None:\n\"\"\"Delete an attribute.\"\"\"\n    delattr(self.__dict__[\"_model\"], name)\n</code></pre>"},{"location":"api/#ml_base.decorator.MLModelDecorator.__getattr__","title":"<code>__getattr__(name)</code>","text":"<p>Get an attribute.</p> Source code in <code>ml_base/decorator.py</code> <pre><code>def __getattr__(self, name: str) -&gt; Any:\n\"\"\"Get an attribute.\"\"\"\n    if name in MLModelDecorator._decorator_attributes:\n        return self.__dict__[name]\n    else:\n        return getattr(self.__dict__[\"_model\"], name)\n</code></pre>"},{"location":"api/#ml_base.decorator.MLModelDecorator.__init__","title":"<code>__init__(model=None, **kwargs)</code>","text":"<p>Initialize MLModelDecorator instance.</p> <p>Note</p> <p>The MLModel parameter is optional and does not need to be provided at initialization of the decorator instance.</p> <p>Note</p> <p>This method receives the model instance and stores the reference.</p> Source code in <code>ml_base/decorator.py</code> <pre><code>def __init__(self, model: Optional[MLModel] = None, **kwargs: dict) -&gt; None:\n\"\"\"Initialize MLModelDecorator instance.\n\n    !!! note\n        The MLModel parameter is optional and does not need to be provided at initialization of the decorator\n        instance.\n\n    !!! note\n        This method receives the model instance and stores the reference.\n\n    \"\"\"\n    if model is not None and not isinstance(model, MLModel):\n        raise ValueError(\"Only objects of type MLModel can be wrapped with MLModelDecorator instances.\")\n\n    self.__dict__[\"_model\"] = model\n    self.__dict__[\"_configuration\"] = kwargs\n</code></pre>"},{"location":"api/#ml_base.decorator.MLModelDecorator.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string describing the decorator and the model that it is decorating.</p> Source code in <code>ml_base/decorator.py</code> <pre><code>def __repr__(self) -&gt; str:\n\"\"\"Return a string describing the decorator and the model that it is decorating.\"\"\"\n    return \"{}({})\".format(self.__class__.__name__, str(self.__dict__[\"_model\"]))\n</code></pre>"},{"location":"api/#ml_base.decorator.MLModelDecorator.__setattr__","title":"<code>__setattr__(name, value)</code>","text":"<p>Set an attribute.</p> Source code in <code>ml_base/decorator.py</code> <pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n\"\"\"Set an attribute.\"\"\"\n    if name in MLModelDecorator._decorator_attributes:\n        setattr(self, name, value)\n    else:\n        setattr(self.__dict__[\"_model\"], name, value)\n</code></pre>"},{"location":"api/#ml_base.decorator.MLModelDecorator.predict","title":"<code>predict(data)</code>","text":"<p>Predict with the model.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>BaseModel</code> <p>Data used by the model for making a prediction.</p> required <p>Returns:</p> Type Description <code>BaseModel</code> <p>python object -- can be any python type</p> <p>Note</p> <p>Unless this method is overridden, the implementation just calls the predict method of the model that is being decorated and returns the result.</p> Source code in <code>ml_base/decorator.py</code> <pre><code>def predict(self, data: BaseModel) -&gt; BaseModel:\n\"\"\"Predict with the model.\n\n    Params:\n        data: Data used by the model for making a prediction.\n\n    Returns:\n        python object -- can be any python type\n\n    !!! note\n        Unless this method is overridden, the implementation just calls the predict method of the\n        model that is being decorated and returns the result.\n\n    \"\"\"\n    return getattr(self, \"_model\").predict(data=data)\n</code></pre>"},{"location":"api/#ml_base.decorator.MLModelDecorator.set_model","title":"<code>set_model(model)</code>","text":"<p>Set a model in the decorator instance.</p> Source code in <code>ml_base/decorator.py</code> <pre><code>def set_model(self, model: MLModel) -&gt; \"MLModelDecorator\":\n\"\"\"Set a model in the decorator instance.\"\"\"\n    if not isinstance(model, MLModel):\n        raise ValueError(\"Only objects of type MLModel can be wrapped with MLModelDecorator instances.\")\n\n    self.__dict__[\"_model\"] = model\n    return self\n</code></pre>"},{"location":"api/#utilities","title":"Utilities","text":"<p>         Bases: <code>object</code></p> <p>Singleton class that instantiates and manages model objects.</p> Source code in <code>ml_base/utilities/model_manager.py</code> <pre><code>class ModelManager(object):\n\"\"\"Singleton class that instantiates and manages model objects.\"\"\"\n\n    _lock = Lock()\n\n    def __new__(cls) -&gt; \"ModelManager\":  # noqa: D102\n\"\"\"Create and return a new ModelManager instance, after instance is first created it will always be returned.\"\"\"\n        if not hasattr(cls, \"_instance\"):\n            with cls._lock:\n                cls._instance = super(ModelManager, cls).__new__(cls)\n                cls._instance._is_initialized = False\n        return cls._instance\n\n    def __init__(self) -&gt; None:\n\"\"\"Construct ModelManager object.\"\"\"\n        if self._is_initialized is False:  # pytype: disable=attribute-error\n            self._models = []\n            self._is_initialized = True\n\n    @classmethod\n    def clear_instance(cls) -&gt; None:\n\"\"\"Clear singleton instance from class.\"\"\"\n        del cls._instance\n\n    def load_model(self, class_path: str) -&gt; None:\n\"\"\"Import and instantiate an MLModel object from a class path.\n\n        Args:\n            class_path: Class path to the model's MLModel class.\n\n        Raises:\n            ValueError: Raised if the model is not a subtype of MLModel, or if a model with the same qualified name\n                      is already loaded in the ModelManager.\n\n        \"\"\"\n        # splitting the class_path into module path and class name\n        module_path = \".\".join(class_path.split(\".\")[:-1])\n        class_name = class_path.split(\".\")[-1]\n\n        # importing the model class\n        model_module = importlib.import_module(module_path)\n        model_class = getattr(model_module, class_name)\n\n        # instantiating the model object from the class\n        model_object = model_class()\n\n        self.add_model(model_object)\n\n    def add_model(self, model: MLModel) -&gt; None:\n\"\"\"Add a model to the ModelManager.\n\n        Args:\n            model: instance of MLModel\n\n        \"\"\"\n        if not isinstance(model, MLModel):\n            raise ValueError(\"ModelManager instance can only hold references to objects of type MLModel.\")\n\n        if model.qualified_name in [model.qualified_name for model in self._models]:\n            raise ValueError(\"A model with the same qualified name is already in the ModelManager singleton.\")\n\n        # saving the model reference to the models list\n        self._models.append(model)\n\n    def remove_model(self, qualified_name: str) -&gt; None:\n\"\"\"Remove an MLModel object from the ModelManager singleton.\n\n        Args:\n            qualified_name: The qualified name of the model to be returned.\n\n        Raises:\n            ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton.\n\n        \"\"\"\n        # searching the list of model objects to find the one with the right qualified name\n        model = next((model for model in self._models if model.qualified_name == qualified_name), None)\n\n        if model is None:\n            raise ValueError(\"Instance of model '{}' not found in ModelManager.\".format(qualified_name))\n        else:\n            self._models.remove(model)\n\n    def get_models(self) -&gt; List[dict]:\n\"\"\"Get a list of models in the model manager singleton.\n\n        Returns:\n            List of dictionaries containing information about the model instances in the ModelManager singleton.\n\n        !!! note\n            The dictionaries in the list returned by this method contain these keys:\n\n            - display_name\n            - qualified_name\n            - description\n            - version\n\n        \"\"\"\n        model_objects = [{\"display_name\": model.display_name,\n                          \"qualified_name\": model.qualified_name,\n                          \"description\": model.description,\n                          \"version\": model.version} for model in self._models]\n        return model_objects\n\n    def get_model_metadata(self, qualified_name: str) -&gt; dict:\n\"\"\"Get model metadata by qualified name.\n\n        Args:\n            qualified_name: Qualified name of the model for which to get metadata\n\n        Returns:\n            Dictionary containing information about a model in the ModelManager singleton.\n\n        !!! note\n            The dictionaries in the list returned by this method contain these keys:\n\n            - display_name\n            - qualified_name\n            - description\n            - version\n            - input_schema\n            - output_schema\n\n        \"\"\"\n        # searching the list of model objects to find the one with the right qualified name\n        model = next((model for model in self._models if model.qualified_name == qualified_name), None)\n\n        if model is None:\n            raise ValueError(\"Instance of model '{}' not found in ModelManager.\".format(qualified_name))\n        else:\n            return {\n                \"display_name\": model.display_name,\n                \"qualified_name\": model.qualified_name,\n                \"description\": model.description,\n                \"version\": model.version,\n                \"input_schema\": model.input_schema.schema(),\n                \"output_schema\": model.output_schema.schema()\n            }\n\n    def get_model(self, qualified_name: str) -&gt; MLModel:\n\"\"\"Get a model object by qualified name.\n\n        Args:\n            qualified_name: The qualified name of the model to be returned.\n\n        Returns:\n            Model object\n\n        Raises:\n            ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton.\n\n        \"\"\"\n        # searching the list of model objects to find the one with the right qualified name\n        model = next((model for model in self._models if model.qualified_name == qualified_name), None)\n\n        if model is None:\n            raise ValueError(\"Instance of model '{}' not found in ModelManager.\".format(qualified_name))\n        else:\n            return model\n\n    def add_decorator(self, qualified_name: str, decorator: MLModelDecorator) -&gt; None:\n\"\"\"Add a decorator to a model object by qualified name.\n\n        Args:\n            qualified_name: The qualified name of the model to add decorator to.\n            decorator: MLModelDecorator instance to apply to model instance.\n\n        Returns:\n            None\n\n        Raises:\n            ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton.\n\n        \"\"\"\n        # searching the list of model objects to find the one with the right qualified name\n        model = next((model for model in self._models if model.qualified_name == qualified_name), None)\n\n        if model is None:\n            raise ValueError(\"Instance of model '{}' not found in ModelManager.\".format(qualified_name))\n\n        # removing old model reference\n        self.remove_model(qualified_name)\n\n        # adding the decorator to the model object\n        decorated_model = decorator.set_model(model)\n\n        # adding the decorated model to the collection\n        self.add_model(decorated_model)\n</code></pre>"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.__init__","title":"<code>__init__()</code>","text":"<p>Construct ModelManager object.</p> Source code in <code>ml_base/utilities/model_manager.py</code> <pre><code>def __init__(self) -&gt; None:\n\"\"\"Construct ModelManager object.\"\"\"\n    if self._is_initialized is False:  # pytype: disable=attribute-error\n        self._models = []\n        self._is_initialized = True\n</code></pre>"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.__new__","title":"<code>__new__()</code>","text":"<p>Create and return a new ModelManager instance, after instance is first created it will always be returned.</p> Source code in <code>ml_base/utilities/model_manager.py</code> <pre><code>def __new__(cls) -&gt; \"ModelManager\":  # noqa: D102\n\"\"\"Create and return a new ModelManager instance, after instance is first created it will always be returned.\"\"\"\n    if not hasattr(cls, \"_instance\"):\n        with cls._lock:\n            cls._instance = super(ModelManager, cls).__new__(cls)\n            cls._instance._is_initialized = False\n    return cls._instance\n</code></pre>"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.add_decorator","title":"<code>add_decorator(qualified_name, decorator)</code>","text":"<p>Add a decorator to a model object by qualified name.</p> <p>Parameters:</p> Name Type Description Default <code>qualified_name</code> <code>str</code> <p>The qualified name of the model to add decorator to.</p> required <code>decorator</code> <code>MLModelDecorator</code> <p>MLModelDecorator instance to apply to model instance.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Raised if a model with the qualified name can't be found in the ModelManager singleton.</p> Source code in <code>ml_base/utilities/model_manager.py</code> <pre><code>def add_decorator(self, qualified_name: str, decorator: MLModelDecorator) -&gt; None:\n\"\"\"Add a decorator to a model object by qualified name.\n\n    Args:\n        qualified_name: The qualified name of the model to add decorator to.\n        decorator: MLModelDecorator instance to apply to model instance.\n\n    Returns:\n        None\n\n    Raises:\n        ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton.\n\n    \"\"\"\n    # searching the list of model objects to find the one with the right qualified name\n    model = next((model for model in self._models if model.qualified_name == qualified_name), None)\n\n    if model is None:\n        raise ValueError(\"Instance of model '{}' not found in ModelManager.\".format(qualified_name))\n\n    # removing old model reference\n    self.remove_model(qualified_name)\n\n    # adding the decorator to the model object\n    decorated_model = decorator.set_model(model)\n\n    # adding the decorated model to the collection\n    self.add_model(decorated_model)\n</code></pre>"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.add_model","title":"<code>add_model(model)</code>","text":"<p>Add a model to the ModelManager.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>MLModel</code> <p>instance of MLModel</p> required Source code in <code>ml_base/utilities/model_manager.py</code> <pre><code>def add_model(self, model: MLModel) -&gt; None:\n\"\"\"Add a model to the ModelManager.\n\n    Args:\n        model: instance of MLModel\n\n    \"\"\"\n    if not isinstance(model, MLModel):\n        raise ValueError(\"ModelManager instance can only hold references to objects of type MLModel.\")\n\n    if model.qualified_name in [model.qualified_name for model in self._models]:\n        raise ValueError(\"A model with the same qualified name is already in the ModelManager singleton.\")\n\n    # saving the model reference to the models list\n    self._models.append(model)\n</code></pre>"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.clear_instance","title":"<code>clear_instance()</code>  <code>classmethod</code>","text":"<p>Clear singleton instance from class.</p> Source code in <code>ml_base/utilities/model_manager.py</code> <pre><code>@classmethod\ndef clear_instance(cls) -&gt; None:\n\"\"\"Clear singleton instance from class.\"\"\"\n    del cls._instance\n</code></pre>"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.get_model","title":"<code>get_model(qualified_name)</code>","text":"<p>Get a model object by qualified name.</p> <p>Parameters:</p> Name Type Description Default <code>qualified_name</code> <code>str</code> <p>The qualified name of the model to be returned.</p> required <p>Returns:</p> Type Description <code>MLModel</code> <p>Model object</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Raised if a model with the qualified name can't be found in the ModelManager singleton.</p> Source code in <code>ml_base/utilities/model_manager.py</code> <pre><code>def get_model(self, qualified_name: str) -&gt; MLModel:\n\"\"\"Get a model object by qualified name.\n\n    Args:\n        qualified_name: The qualified name of the model to be returned.\n\n    Returns:\n        Model object\n\n    Raises:\n        ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton.\n\n    \"\"\"\n    # searching the list of model objects to find the one with the right qualified name\n    model = next((model for model in self._models if model.qualified_name == qualified_name), None)\n\n    if model is None:\n        raise ValueError(\"Instance of model '{}' not found in ModelManager.\".format(qualified_name))\n    else:\n        return model\n</code></pre>"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.get_model_metadata","title":"<code>get_model_metadata(qualified_name)</code>","text":"<p>Get model metadata by qualified name.</p> <p>Parameters:</p> Name Type Description Default <code>qualified_name</code> <code>str</code> <p>Qualified name of the model for which to get metadata</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing information about a model in the ModelManager singleton.</p> <p>Note</p> <p>The dictionaries in the list returned by this method contain these keys:</p> <ul> <li>display_name</li> <li>qualified_name</li> <li>description</li> <li>version</li> <li>input_schema</li> <li>output_schema</li> </ul> Source code in <code>ml_base/utilities/model_manager.py</code> <pre><code>def get_model_metadata(self, qualified_name: str) -&gt; dict:\n\"\"\"Get model metadata by qualified name.\n\n    Args:\n        qualified_name: Qualified name of the model for which to get metadata\n\n    Returns:\n        Dictionary containing information about a model in the ModelManager singleton.\n\n    !!! note\n        The dictionaries in the list returned by this method contain these keys:\n\n        - display_name\n        - qualified_name\n        - description\n        - version\n        - input_schema\n        - output_schema\n\n    \"\"\"\n    # searching the list of model objects to find the one with the right qualified name\n    model = next((model for model in self._models if model.qualified_name == qualified_name), None)\n\n    if model is None:\n        raise ValueError(\"Instance of model '{}' not found in ModelManager.\".format(qualified_name))\n    else:\n        return {\n            \"display_name\": model.display_name,\n            \"qualified_name\": model.qualified_name,\n            \"description\": model.description,\n            \"version\": model.version,\n            \"input_schema\": model.input_schema.schema(),\n            \"output_schema\": model.output_schema.schema()\n        }\n</code></pre>"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.get_models","title":"<code>get_models()</code>","text":"<p>Get a list of models in the model manager singleton.</p> <p>Returns:</p> Type Description <code>List[dict]</code> <p>List of dictionaries containing information about the model instances in the ModelManager singleton.</p> <p>Note</p> <p>The dictionaries in the list returned by this method contain these keys:</p> <ul> <li>display_name</li> <li>qualified_name</li> <li>description</li> <li>version</li> </ul> Source code in <code>ml_base/utilities/model_manager.py</code> <pre><code>def get_models(self) -&gt; List[dict]:\n\"\"\"Get a list of models in the model manager singleton.\n\n    Returns:\n        List of dictionaries containing information about the model instances in the ModelManager singleton.\n\n    !!! note\n        The dictionaries in the list returned by this method contain these keys:\n\n        - display_name\n        - qualified_name\n        - description\n        - version\n\n    \"\"\"\n    model_objects = [{\"display_name\": model.display_name,\n                      \"qualified_name\": model.qualified_name,\n                      \"description\": model.description,\n                      \"version\": model.version} for model in self._models]\n    return model_objects\n</code></pre>"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.load_model","title":"<code>load_model(class_path)</code>","text":"<p>Import and instantiate an MLModel object from a class path.</p> <p>Parameters:</p> Name Type Description Default <code>class_path</code> <code>str</code> <p>Class path to the model's MLModel class.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Raised if the model is not a subtype of MLModel, or if a model with the same qualified name       is already loaded in the ModelManager.</p> Source code in <code>ml_base/utilities/model_manager.py</code> <pre><code>def load_model(self, class_path: str) -&gt; None:\n\"\"\"Import and instantiate an MLModel object from a class path.\n\n    Args:\n        class_path: Class path to the model's MLModel class.\n\n    Raises:\n        ValueError: Raised if the model is not a subtype of MLModel, or if a model with the same qualified name\n                  is already loaded in the ModelManager.\n\n    \"\"\"\n    # splitting the class_path into module path and class name\n    module_path = \".\".join(class_path.split(\".\")[:-1])\n    class_name = class_path.split(\".\")[-1]\n\n    # importing the model class\n    model_module = importlib.import_module(module_path)\n    model_class = getattr(model_module, class_name)\n\n    # instantiating the model object from the class\n    model_object = model_class()\n\n    self.add_model(model_object)\n</code></pre>"},{"location":"api/#ml_base.utilities.model_manager.ModelManager.remove_model","title":"<code>remove_model(qualified_name)</code>","text":"<p>Remove an MLModel object from the ModelManager singleton.</p> <p>Parameters:</p> Name Type Description Default <code>qualified_name</code> <code>str</code> <p>The qualified name of the model to be returned.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Raised if a model with the qualified name can't be found in the ModelManager singleton.</p> Source code in <code>ml_base/utilities/model_manager.py</code> <pre><code>def remove_model(self, qualified_name: str) -&gt; None:\n\"\"\"Remove an MLModel object from the ModelManager singleton.\n\n    Args:\n        qualified_name: The qualified name of the model to be returned.\n\n    Raises:\n        ValueError: Raised if a model with the qualified name can't be found in the ModelManager singleton.\n\n    \"\"\"\n    # searching the list of model objects to find the one with the right qualified name\n    model = next((model for model in self._models if model.qualified_name == qualified_name), None)\n\n    if model is None:\n        raise ValueError(\"Instance of model '{}' not found in ModelManager.\".format(qualified_name))\n    else:\n        self._models.remove(model)\n</code></pre>"},{"location":"basic/","title":"Introducing the ml_base Package","text":"<p>These examples run within an Jupyter notebook session. To clear out the results of cells that we don't want to see we'll use the clear_output() function provided by Jupyter:</p> <pre><code>from IPython.display import clear_output\n</code></pre> <p>To get started we'll install the ml_base package:</p> <pre><code>!pip install ml_base\n\nclear_output()\n</code></pre>"},{"location":"basic/#creating-a-simple-model","title":"Creating a Simple Model","text":"<p>To show how to work with the MLModel base class we'll create a simple model that we can make predictions with. We'll use the scikit-learn library, so we'll need to install it:</p> <pre><code>!pip install scikit-learn\n\nclear_output()\n</code></pre> <p>Now we can write some code to train a model:</p> <pre><code>from sklearn import datasets\nfrom sklearn import svm\nimport pickle\n\n# loading the Iris dataset\niris = datasets.load_iris()\n\n# instantiating an SVM model from scikit-learn\nsvm_model = svm.SVC(gamma=1.0, C=1.0)\n\n# fitting the model\nsvm_model.fit(iris.data[:-1], iris.target[:-1])\n\n# serializing the model and saving it\nfile = open(\"svc_model.pickle\", 'wb')\npickle.dump(svm_model, file)\nfile.close()\n</code></pre>"},{"location":"basic/#creating-a-wrapper-class-for-your-model","title":"Creating a Wrapper Class for Your Model","text":"<p>Now that we have a model object, we'll define a class that implements the prediction functionality for the code:</p> <pre><code>import os\nfrom numpy import array\n\n\nclass IrisModel(object):\n    def __init__(self):\n        dir_path = os.path.abspath('')\n        file = open(os.path.join(dir_path, \"svc_model.pickle\"), 'rb')\n        self._svm_model = pickle.load(file)\n        file.close()\n\n    def predict(self, data: dict):\n        X = array([data[\"sepal_length\"], data[\"sepal_width\"], data[\"petal_length\"], data[\"petal_width\"]]).reshape(1, -1)\n        y_hat = int(self._svm_model.predict(X)[0])\n        targets = ['setosa', 'versicolor', 'virginica']\n        species = targets[y_hat]\n        return {\"species\": species}\n</code></pre> <p>The class above wraps the pickled model object and makes the model easier to use by converting the inputs and outputs. To use the model, all we need to do is this:</p> <pre><code>model = IrisModel()\n\nprediction = model.predict(data={\n    \"sepal_length\":1.0,\n    \"sepal_width\":1.1,\n    \"petal_length\": 1.2,\n    \"petal_width\": 1.3})\n\nprediction\n</code></pre> <pre><code>{'species': 'virginica'}\n</code></pre>"},{"location":"basic/#creating-an-mlmodel-class-for-your-model","title":"Creating an MLModel Class for Your Model","text":"<p>The model is already much easier to use because it provides the prediction from a class. The user of the model doesn't need to worry about loading the pickled model object, or converting the model's input into a numpy array. However, we are still not using the MLModel abstract base class, now we'll implement a part of the MLModel's interface to show how it works:</p> <pre><code>from ml_base import MLModel\n\n\nclass IrisModel(MLModel):\n    @property\n    def display_name(self):\n        return \"Iris Model\"\n\n    @property\n    def qualified_name(self):\n        return \"iris_model\"\n\n    @property\n    def description(self):\n        return \"A model to predict the species of a flower based on its measurements.\"\n\n    @property\n    def version(self):\n        return \"1.0.0\"\n\n    @property\n    def input_schema(self):\n        raise NotImplementedError()\n\n    @property\n    def output_schema(self):\n        raise NotImplementedError()\n\n    def __init__(self):\n        dir_path = os.path.abspath('')\n        file = open(os.path.join(dir_path, \"svc_model.pickle\"), 'rb')\n        self._svm_model = pickle.load(file)\n        file.close()\n\n    def predict(self, data: dict):\n        X = array([data[\"sepal_length\"], data[\"sepal_width\"], data[\"petal_length\"], data[\"petal_width\"]]).reshape(1, -1)\n        y_hat = int(self._svm_model.predict(X)[0])\n        targets = ['setosa', 'versicolor', 'virginica']\n        species = targets[y_hat]\n        return {\"species\": species}\n</code></pre> <p>The MLModel base class defines a set of properties that must be provided by any class that inherits from it. Because the IrisModel class now provides this metadata about the model, we can access it directly from the model object like this:</p> <pre><code>model = IrisModel()\n\nprint(model.qualified_name)\n</code></pre> <pre><code>iris_model\n</code></pre> <p>The qualified name of the model uniquely identifies the instance of the model within the system. Right now the qualified name is hardcoded in the code of the model's class, but this can be made more dynamic in the future. The qualified name should also be a string that is easy to embed in a URL, so it shouldn't have spaces or special characters.</p> <p>The model's display name is also available from the model object:</p> <pre><code>print(model.display_name)\n</code></pre> <pre><code>Iris Model\n</code></pre> <p>The display name of a model should be a string that looks good in a user interface.</p> <p>The model description is also available from the model object:</p> <pre><code>print(model.description)\n</code></pre> <pre><code>A model to predict the species of a flower based on its measurements.\n</code></pre> <p>The model version is also available as a string from the model object:</p> <pre><code>print(model.version)\n</code></pre> <pre><code>1.0.0\n</code></pre> <p>As you can see, we didn't implement the input_schema and output_schema properties above, we'll add those next.</p>"},{"location":"basic/#adding-schemas-to-your-model","title":"Adding Schemas to Your Model","text":"<p>To add schema information to the model class, we'll use the pydantic package. The pydantic package allows us to state the schema requirements of the model's input and output programatically as Python classes:</p> <pre><code>from pydantic import BaseModel, Field\nfrom pydantic import ValidationError\nfrom enum import Enum\n\n\nclass ModelInput(BaseModel):\n    sepal_length: float = Field(gt=5.0, lt=8.0, description=\"The length of the sepal of the flower.\")\n    sepal_width: float = Field(gt=2.0, lt=6.0, description=\"The width of the sepal of the flower.\")\n    petal_length: float = Field(gt=1.0, lt=6.8, description=\"The length of the petal of the flower.\")\n    petal_width: float = Field(gt=0.0, lt=3.0, description=\"The width of the petal of the flower.\")\n\n\nclass Species(str, Enum):\n    iris_setosa = \"Iris setosa\"\n    iris_versicolor = \"Iris versicolor\"\n    iris_virginica = \"Iris virginica\"\n\n\nclass ModelOutput(BaseModel):\n    species: Species = Field(description=\"The predicted species of the flower.\")\n\n</code></pre> <p>The ModelInput class inherits from the pydantic BaseModel class and it defines four required fields, all of them floating point numbers. The pydantic package allows for defining upper bounds and lower bounds for the values accepted by each field, and also a description for the field.</p> <p>The ModelOutput is made up of a single fields, which is an enumerated string that contains the predicted species of the flower.</p> <p>Now that we have the ModelInput and ModelOutput schemas defined as pydantic BaseModel classes, we'll add them to the IrisModel class by returning them from the input_schema and output_schema properties:</p> <pre><code>from ml_base.ml_model import MLModel, MLModelSchemaValidationException\n\n\nclass IrisModel(MLModel):\n    @property\n    def display_name(self):\n        return \"Iris Model\"\n\n    @property\n    def qualified_name(self):\n        return \"iris_model\"\n\n    @property\n    def description(self):\n        return \"A model to predict the species of a flower based on its measurements.\"\n\n    @property\n    def version(self):\n        return \"1.0.0\"\n\n    @property\n    def input_schema(self):\n        return ModelInput\n\n    @property\n    def output_schema(self):\n        return ModelOutput\n\n    def __init__(self):\n        dir_path = os.path.abspath('')\n        with open(os.path.join(dir_path, \"svc_model.pickle\"), 'rb') as f:\n            self._svm_model = pickle.load(f)\n\n    def predict(self, data: ModelInput):\n        # creating a numpy array using the fields in the input object\n        X = array([data.sepal_length, \n                   data.sepal_width, \n                   data.petal_length, \n                   data.petal_width]).reshape(1, -1)\n\n        # making a prediction, at this point its a number\n        y_hat = int(self._svm_model.predict(X)[0])\n\n        # converting the prediction from a number to a string\n        targets = [\"Iris setosa\", \"Iris versicolor\", \"Iris virginica\"]\n        species = targets[y_hat]\n\n        # returning the prediction inside an object\n        return ModelOutput(species=species)\n</code></pre> <p>Notice that we are also using the pydantic models to validate the input before prediction and to create an object that will be returned from the model's predict() method.</p> <p>If we use the model class now, we'll get this result:</p> <pre><code>model = IrisModel()\n\nprediction = model.predict(ModelInput(\n    sepal_length=6.0, \n    sepal_width=2.1, \n    petal_length=1.2, \n    petal_width=1.3))\n\nprediction\n</code></pre> <pre><code>ModelOutput(species=&lt;Species.iris_virginica: 'Iris virginica'&gt;)\n</code></pre> <p>By adding input and output schemas to the model, we can automate many other operations later. Also, we can query the model object itself for the schema. The pydantic package is able to create JSON schema from the fields in the input and output schema objects of the model:</p> <pre><code>model = IrisModel()\n\nmodel.input_schema.schema()\n</code></pre> <pre><code>{'title': 'ModelInput',\n 'type': 'object',\n 'properties': {'sepal_length': {'title': 'Sepal Length',\n   'description': 'The length of the sepal of the flower.',\n   'exclusiveMinimum': 5.0,\n   'exclusiveMaximum': 8.0,\n   'type': 'number'},\n  'sepal_width': {'title': 'Sepal Width',\n   'description': 'The width of the sepal of the flower.',\n   'exclusiveMinimum': 2.0,\n   'exclusiveMaximum': 6.0,\n   'type': 'number'},\n  'petal_length': {'title': 'Petal Length',\n   'description': 'The length of the petal of the flower.',\n   'exclusiveMinimum': 1.0,\n   'exclusiveMaximum': 6.8,\n   'type': 'number'},\n  'petal_width': {'title': 'Petal Width',\n   'description': 'The width of the petal of the flower.',\n   'exclusiveMinimum': 0.0,\n   'exclusiveMaximum': 3.0,\n   'type': 'number'}},\n 'required': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']}\n</code></pre> <pre><code>model.output_schema.schema()\n</code></pre> <pre><code>{'title': 'ModelOutput',\n 'type': 'object',\n 'properties': {'species': {'$ref': '#/definitions/Species'}},\n 'required': ['species'],\n 'definitions': {'Species': {'title': 'Species',\n   'description': 'An enumeration.',\n   'enum': ['Iris setosa', 'Iris versicolor', 'Iris virginica'],\n   'type': 'string'}}}\n</code></pre> <p>Although it is not required to use the pydantic package to create model schemas, it is recommended. The pydantic package is installed as a dependency of the ml_base package.</p>"},{"location":"basic/#using-the-modelmanager-class","title":"Using the ModelManager Class","text":"<p>The ModelManager class is provided to help manage model objects. It is a singleton class that is designed to enable model instances to be instantiated once during the lifecycle of a process and accessed many times:</p> <pre><code>from ml_base.utilities import ModelManager\n\n\nmodel_manager = ModelManager()\n</code></pre> <p>Because it is a singleton object, a reference to the same object is returned no matter how many times we instantiate it:</p> <pre><code>print(id(model_manager))\n\nanother_model_manager = ModelManager()\n\nprint(id(another_model_manager))\n</code></pre> <pre><code>4505980208\n4505980208\n</code></pre> <p>You can add model instances to the ModelManager singleton by asking it to instantiate the model class:</p> <pre><code>model_manager.load_model(\"__main__.IrisModel\")\n</code></pre> <p>The load_model() method is able to find the MLModel class that we defined above and instantiate it, after that it stores a reference to the instance internally.</p> <p>The ModelManager is also able to save references to model instances that were instantiated in some other way by using the add_model() method:</p> <pre><code>another_iris_model = IrisModel()\n\ntry:\n    model_manager.add_model(another_iris_model)\nexcept ValueError as e:\n    print(e)\n</code></pre> <pre><code>A model with the same qualified name is already in the ModelManager singleton.\n</code></pre> <p>In this case, the ModelManager did not save the instance of the IrisModel because we already had an instance of the model. The models are uniquely identified by their qualified name properties.</p> <p>The ModelManager instance can list the models that it contains with the get_models() method, the details of the instance of IrisModel that we just created are returned:</p> <pre><code>model_manager.get_models()\n</code></pre> <pre><code>[{'display_name': 'Iris Model',\n  'qualified_name': 'iris_model',\n  'description': 'A model to predict the species of a flower based on its measurements.',\n  'version': '1.0.0'}]\n</code></pre> <p>The ModelManager instance can return the metadata of any of the models. The metadata includes the input and output schemas as well:</p> <pre><code>model_manager.get_model_metadata(\"iris_model\")\n</code></pre> <pre><code>{'display_name': 'Iris Model',\n 'qualified_name': 'iris_model',\n 'description': 'A model to predict the species of a flower based on its measurements.',\n 'version': '1.0.0',\n 'input_schema': {'title': 'ModelInput',\n  'type': 'object',\n  'properties': {'sepal_length': {'title': 'Sepal Length',\n    'description': 'The length of the sepal of the flower.',\n    'exclusiveMinimum': 5.0,\n    'exclusiveMaximum': 8.0,\n    'type': 'number'},\n   'sepal_width': {'title': 'Sepal Width',\n    'description': 'The width of the sepal of the flower.',\n    'exclusiveMinimum': 2.0,\n    'exclusiveMaximum': 6.0,\n    'type': 'number'},\n   'petal_length': {'title': 'Petal Length',\n    'description': 'The length of the petal of the flower.',\n    'exclusiveMinimum': 1.0,\n    'exclusiveMaximum': 6.8,\n    'type': 'number'},\n   'petal_width': {'title': 'Petal Width',\n    'description': 'The width of the petal of the flower.',\n    'exclusiveMinimum': 0.0,\n    'exclusiveMaximum': 3.0,\n    'type': 'number'}},\n  'required': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']},\n 'output_schema': {'title': 'ModelOutput',\n  'type': 'object',\n  'properties': {'species': {'$ref': '#/definitions/Species'}},\n  'required': ['species'],\n  'definitions': {'Species': {'title': 'Species',\n    'description': 'An enumeration.',\n    'enum': ['Iris setosa', 'Iris versicolor', 'Iris virginica'],\n    'type': 'string'}}}}\n</code></pre> <p>The ModelManager can return a reference to the instance of any model that it is holding:</p> <pre><code>iris_model = model_manager.get_model(\"iris_model\")\n\nprint(iris_model.display_name)\n</code></pre> <pre><code>Iris Model\n</code></pre> <p>The instance is identified by the qualified name of the model.</p> <p>Lastly, a model instance can be removed by calling the remove_model() method:</p> <pre><code>model_manager.remove_model(\"iris_model\")\n\nmodel_manager.get_models()\n</code></pre> <pre><code>[]\n</code></pre> <p>To clear the ModelManager instance, you can call the clear_instance() method:</p> <pre><code>model_manager.clear_instance()\n</code></pre> <p>To create a new singleton you have to instantiate the ModelManager again:</p> <pre><code>model_manager = ModelManager()\n</code></pre>"},{"location":"decorator/","title":"MLModelDecorator Example","text":"<pre><code>import sys\nimport os\n\nsys.path.insert(0, os.path.abspath(os.path.join(\"./\", os.pardir)))\n</code></pre>"},{"location":"decorator/#creating-a-decorator","title":"Creating a Decorator","text":"<p>Decorators are objects that allow us to extend the functionality of other objects at runtime without having to modify the objects that are being decorated. The decorator pattern is a well-known object-oriented design pattern that helps to make code more flexible and reusable.</p> <p>Notice that we are not working with Python decorators, which are used to decorate functions and methods at loading time only (when the function or class is created). The decorators we will work with are run-time decorators since they are applied during the runtime of the program.</p> <p>The objects we want to decorate are MLModel objects, so we'll need an MLModel class to work with. We'll create a simple mocked model class to work with along with the input and output schemas:</p> <pre><code>from ml_base.ml_model import MLModel\nfrom pydantic import BaseModel, Field\nfrom enum import Enum\n\n\nclass ModelInput(BaseModel):\n    sepal_length: float = Field(gt=5.0, lt=8.0)\n    sepal_width: float = Field(gt=2.0, lt=6.0)\n    petal_length: float = Field(gt=1.0, lt=6.8)\n    petal_width: float = Field(gt=0.0, lt=3.0)\n\n\nclass Species(str, Enum):\n    iris_setosa = \"Iris setosa\"\n    iris_versicolor = \"Iris versicolor\"\n    iris_virginica = \"Iris virginica\"\n\n\nclass ModelOutput(BaseModel):\n    species: Species\n\n\nclass IrisModelMock(MLModel):\n    display_name = \"Iris Model\"\n    qualified_name = \"iris_model\"\n    description = \"A model to predict the species of a flower based on its measurements.\"\n    version = \"1.0.0\"\n    input_schema = ModelInput\n    output_schema = ModelOutput\n\n    def __init__(self):\n        pass\n\n    def predict(self, data: ModelInput) -&gt; ModelOutput:\n        return ModelOutput(species=\"Iris setosa\")\n</code></pre> <p>This class mocks the input and output of the IrisModel we used in the previous example. The mocked model will always return a prediction of \"Iris setosa\". We'll instantiate it to make sure that everything works:</p> <pre><code>model = IrisModelMock()\n\nprediction = model.predict(\n    ModelInput(sepal_length=5.1,\n               sepal_width=2.2,\n               petal_length=1.2,\n               petal_width=1.3))\n\nprediction\n</code></pre> <pre><code>ModelOutput(species=&lt;Species.iris_setosa: 'Iris setosa'&gt;)\n</code></pre>"},{"location":"decorator/#creating-a-simple-decorator-class","title":"Creating a Simple Decorator Class","text":"<p>To create a decorator for MLModel classes, we'll inherit from the MLModelDecorator class:</p> <pre><code>from ml_base import MLModelDecorator\nfrom ml_base.ml_model import MLModelException\n\n\nclass SimpleDecorator(MLModelDecorator):\n    pass\n</code></pre> <p>The decorator doesn't do anything but it's still useful because it inherits default behavior from the base class. In order to wrap the model instance with a decorator instance, we instantiate the decorator like this:</p> <pre><code>decorator = SimpleDecorator(model)\n</code></pre> <p>Now we can make a prediction with the model just like we normally would:</p> <pre><code>prediction = decorator.predict(\n    ModelInput(sepal_length=5.1,\n               sepal_width=2.2,\n               petal_length=1.2,\n               petal_width=1.3))\n\nprint(prediction)\n</code></pre> <pre><code>species=&lt;Species.iris_setosa: 'Iris setosa'&gt;\n</code></pre> <p>The decorator's default implementation of the predict method does nothing but call the corresponding method in the model instance. The same is true for the other parts of the MLModel API.</p> <pre><code>print(decorator.display_name)\nprint(decorator.qualified_name)\nprint(decorator.description)\nprint(decorator.version)\nprint(decorator.input_schema)\nprint(decorator.output_schema)\n</code></pre> <pre><code>Iris Model\niris_model\nA model to predict the species of a flower based on its measurements.\n1.0.0\n&lt;class '__main__.ModelInput'&gt;\n&lt;class '__main__.ModelOutput'&gt;\n</code></pre>"},{"location":"decorator/#creating-an-mlmodeldecorator-with-behavior","title":"Creating an MLModelDecorator With Behavior","text":"<p>The example above wasn't very useful because it didn't do anything. We'll override the default implementation of the MLModelDecorator base class in order to add some behavior.</p> <p>This decorator executes around the predict() method:</p> <pre><code>class SimplePredictDecorator(MLModelDecorator):\n\n    def predict(self, data):\n        print(\"Executing before prediction.\")\n        prediction = self._model.predict(data=data)\n        print(\"Executing after prediction.\")\n        return prediction\n</code></pre> <p>The decorator wraps around the predict() method and does nothing except print a message before and after executing the predict method of the model.</p> <p>We can try it out by wrapping the model instance again:</p> <pre><code>decorator = SimplePredictDecorator(model)\n</code></pre> <p>Now, we'll call the predict method:</p> <pre><code>prediction = decorator.predict(ModelInput(\n    sepal_length=5.1,\n    sepal_width=2.1,\n    petal_length=1.2,\n    petal_width=1.3))\n\nprediction\n</code></pre> <pre><code>Executing before prediction.\nExecuting after prediction.\n\n\n\n\n\nModelOutput(species=&lt;Species.iris_setosa: 'Iris setosa'&gt;)\n</code></pre> <p>The decorator instance executed before and after the model's predict() method and printed some messages.</p>"},{"location":"decorator/#a-more-complex-decorator","title":"A More Complex Decorator","text":"<p>The MLModelDecorator class is able to \"wrap\" every method and property in the MLModel base class. We'll build a more complex MLModelDecorator to show how this works:</p> <pre><code>class ComplexDecorator(MLModelDecorator):\n\n    @property\n    def display_name(self) -&gt; str:\n        return self._model.display_name + \" extra\"\n\n    @property\n    def qualified_name(self) -&gt; str:\n        return self._model.qualified_name + \" extra\"\n\n    @property\n    def description(self) -&gt; str:\n        return self._model.description + \" extra\"\n\n    @property\n    def version(self) -&gt; str:\n        return self._model.version + \" extra\"\n\n    def predict(self, data):\n        print(\"Executing before prediction.\")\n        prediction = self._model.predict(data=data)\n        print(\"Executing after prediction.\")\n        return prediction\n</code></pre> <pre><code>complex_decorator = ComplexDecorator(model)\n\nprint(complex_decorator.display_name)\nprint(complex_decorator.qualified_name)\nprint(complex_decorator.description)\nprint(complex_decorator.version)\n</code></pre> <pre><code>Iris Model extra\niris_model extra\nA model to predict the species of a flower based on its measurements. extra\n1.0.0 extra\n</code></pre> <p>The properties of the MLModel instance were modifyied by adding the word \"extra\" to them, including the input and output schemas, although it would not be a good idea to convert the schema classes to strings in a normal situation.</p> <p>Any other methods, attributes, or properties of an MLModel class that are not part of the MLModel interface are not modified by MLModelDecorator instances that are wrapping them. To show this we'll create an MLModel class with some extra attributes:</p> <pre><code>class IrisModelMockWithExtraAttributes(MLModel):\n    display_name = \"Iris Model\"\n    qualified_name = \"iris_model\"\n    description = \"A model to predict the species of a flower based on its measurements.\"\n    version = \"1.0.0\"\n    input_schema = ModelInput\n    output_schema = ModelOutput\n\n    def __init__(self):\n        self.extra_attribute = \"extra_attribute\"\n\n    def predict(self, data: ModelInput) -&gt; ModelOutput:\n        return ModelOutput(species=\"Iris setosa\")\n\n    @property\n    def extra_property(self):\n        return \"extra_property\"\n\n    def extra_method(self):\n        return \"extra_method\"\n</code></pre> <pre><code>model = IrisModelMockWithExtraAttributes()\n\ndecorator = ComplexDecorator(model)\n\nprint(decorator.extra_attribute)\nprint(decorator.extra_property)\nprint(decorator.extra_method())\n</code></pre> <pre><code>extra_attribute\nextra_property\nextra_method\n</code></pre> <p>The MLModelDecorator class is designed to execute around the public API of the MLModel base class and stay out of the way of any other part of an MLModel instance.</p> <p>When implementing decorators, its important to remember to call the method or return the property of the model instance itself, otherwise the decorator would no longer decorate the model, it would just replace it.</p>"},{"location":"decorator/#setting-the-model-after-initialization","title":"Setting the Model After Initialization","text":"<p>The MLModelDecorator can also be instantiated without a reference to an MLModel instance to decorate.</p> <pre><code>decorator = ComplexDecorator()\n\ndecorator\n</code></pre> <pre><code>ComplexDecorator(None)\n</code></pre> <p>When we print the decorator, whe model reference inside shows up as \"None\".</p> <p>If we try to execute access the API of the decorator, we'll get an error:</p> <pre><code>try:\n    decorator.version\nexcept Exception as e:\n    print(e)\n</code></pre> <pre><code>'NoneType' object has no attribute 'version'\n</code></pre> <p>To set the model instances after initialization, we can use the set_model() method.</p> <pre><code>decorator.set_model(model)\n\ndecorator\n</code></pre> <pre><code>ComplexDecorator(IrisModelMockWithExtraAttributes)\n</code></pre> <p>Accessing the decorator now accesses the model as show above:</p> <pre><code>decorator.version\n</code></pre> <pre><code>'1.0.0 extra'\n</code></pre>"},{"location":"decorator/#displaying-the-decorator","title":"Displaying the Decorator","text":"<p>Once a model instance has been decorated, we can see that it is decorating when we print it:</p> <pre><code>decorator\n</code></pre> <pre><code>ComplexDecorator(IrisModelMockWithExtraAttributes)\n</code></pre> <p>The ComplexDecorator is wrapping an instance of MLModelMock.</p> <p>If we add another decorator, we can see it is decorated again:</p> <pre><code>decorator = SimplePredictDecorator(decorator)\n\ndecorator\n</code></pre> <pre><code>SimplePredictDecorator(ComplexDecorator(IrisModelMockWithExtraAttributes))\n</code></pre> <p>Decorators can decorate other instances of decorators because they have the same API as MLModel.</p>"},{"location":"decorator/#creating-an-exception-handler-decorator","title":"Creating an Exception Handler Decorator","text":"<p>To show a real example of what a decorator can do, we'll create a decorator that handles exceptions raised in the predict() method and logs them.</p> <pre><code>import logging\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass ExceptionLoggerDecorator(MLModelDecorator):\n\n    def predict(self, data):\n        try:\n            return self._model.predict(data=data)\n        except Exception as e:\n            logger.exception(\"Exception in the predict() method of {}.\".format(str(self._model)))\n\n</code></pre> <p>We'll need to raise an exception in the model class' predict() method in order to try this out, so we'll redefine the IrisModelMock class to raise an exception:</p> <pre><code>class IrisModelMock(MLModel):\n    display_name = \"Iris Model\"\n    qualified_name = \"iris_model\"\n    description = \"A model to predict the species of a flower based on its measurements.\"\n    version = \"1.0.0\"\n    input_schema = ModelInput\n    output_schema = ModelOutput\n\n    def __init__(self):\n        pass\n\n    def predict(self, data):\n        raise Exception(\"Exception!\")\n</code></pre> <p>Now all we need is to instantiate the MLModel class and the decorator to try it out:</p> <pre><code>model = IrisModelMock()\n\ndecorator = ExceptionLoggerDecorator(model)\n\n# making a failing prediction\nprediction = decorator.predict(ModelInput(\n    sepal_length=5.1,\n    sepal_width=2.1,\n    petal_length=1.2,\n    petal_width=1.3))\n</code></pre> <pre><code>Exception in the predict() method of IrisModelMock.\nTraceback (most recent call last):\n  File \"&lt;ipython-input-21-ea4dab4c8b70&gt;\", line 11, in predict\n    return self._model.predict(data=data)\n  File \"&lt;ipython-input-22-79739fa901dd&gt;\", line 13, in predict\n    raise Exception(\"Exception!\")\nException: Exception!\n</code></pre> <p>The exception was caught by the decorator and logged.</p>"},{"location":"decorator/#configurable-mlmodel-decorator","title":"Configurable MLModel Decorator","text":"<p>Next, we'll build an MLModelDecorator that can be configured.</p> <pre><code>class AddStringDecorator(MLModelDecorator):\n\n    def __init__(self, model: MLModel, extra_name: str) -&gt; None:\n        super().__init__(model, extra_name=extra_name)\n\n    @property\n    def display_name(self) -&gt; str:\n        return self._model.display_name + self._configuration[\"extra_name\"]\n</code></pre> <p>The __init__() method receives the normal \"model\" parameter and passes it to the super class. It also receives a parameter called \"extra_name\" which is also passed to the super class as a keyword argument. Each configuration items should be passed to the super class in this way.</p> <p>The decorator adds a string to the display_name property of the model object:</p> <pre><code>model = IrisModelMock()\n\ndecorator = AddStringDecorator(model, extra_name=\" extra name\")\n</code></pre> <p>Now when we access the properties, we'll get the string we configured added to the end:</p> <pre><code>print(decorator.display_name)\n</code></pre> <pre><code>Iris Model extra name\n</code></pre> <p>Once the configuration has been passed to the MLModelDecorator super class as a keyword argument, it is saved in the \"_configuration\" attribute and can be accessed by the methods in the decorator class.</p> <p>This also means that the \"_configuration\" and \"_model\" names are reserved within MLModelDecorator classes because they are being used by the base class.</p> <p>You can also set the values in the \"_configuration\" and \"_model\" attributes of the decorator:</p> <pre><code>decorator._configuration[\"asdf\"] = \"asdf\"\n\ndecorator._configuration\n</code></pre> <pre><code>{'extra_name': ' extra name', 'asdf': 'asdf'}\n</code></pre>"},{"location":"decorator/#adding-the-decorated-model-to-the-modelmanager","title":"Adding the Decorated Model to the ModelManager","text":"<p>Adding a decorated model to the ModelManager singleton is simple. First we'll create a decorated model:</p> <pre><code>model = IrisModelMock()\n\ndecorated_model = SimpleDecorator(model)\n</code></pre> <p>Next, we'll create the ModelManager:</p> <pre><code>from ml_base.utilities import ModelManager\n\n\nmodel_manager = ModelManager()\n</code></pre> <p>Finally, we'll add the decorated model as we normally would:</p> <pre><code>model_manager.add_model(decorated_model)\n\nmodel_manager.get_model_metadata(\"iris_model\")\n</code></pre> <pre><code>{'display_name': 'Iris Model',\n 'qualified_name': 'iris_model',\n 'description': 'A model to predict the species of a flower based on its measurements.',\n 'version': '1.0.0',\n 'input_schema': {'title': 'ModelInput',\n  'type': 'object',\n  'properties': {'sepal_length': {'title': 'Sepal Length',\n    'exclusiveMinimum': 5.0,\n    'exclusiveMaximum': 8.0,\n    'type': 'number'},\n   'sepal_width': {'title': 'Sepal Width',\n    'exclusiveMinimum': 2.0,\n    'exclusiveMaximum': 6.0,\n    'type': 'number'},\n   'petal_length': {'title': 'Petal Length',\n    'exclusiveMinimum': 1.0,\n    'exclusiveMaximum': 6.8,\n    'type': 'number'},\n   'petal_width': {'title': 'Petal Width',\n    'exclusiveMinimum': 0.0,\n    'exclusiveMaximum': 3.0,\n    'type': 'number'}},\n  'required': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']},\n 'output_schema': {'title': 'ModelOutput',\n  'type': 'object',\n  'properties': {'species': {'$ref': '#/definitions/Species'}},\n  'required': ['species'],\n  'definitions': {'Species': {'title': 'Species',\n    'description': 'An enumeration.',\n    'enum': ['Iris setosa', 'Iris versicolor', 'Iris virginica'],\n    'type': 'string'}}}}\n</code></pre> <p>The ModelManager is able to work with the decorated model object because it has the same interface as MLModel.</p> <pre><code>model_manager.clear_instance()\n</code></pre>"},{"location":"decorator/#adding-a-decorator-to-a-model-in-the-modelmanager","title":"Adding a Decorator to a Model in the ModelManager","text":"<p>The ModelManager also has support for decorating models that are already held inside by using the add_decorator() method:</p> <pre><code>from ml_base.utilities import ModelManager\n\nmodel_manager = ModelManager()\n\nmodel = IrisModelMock()\n\nmodel_manager.add_model(model)\n\nprint(model_manager.get_models())\n</code></pre> <pre><code>[{'display_name': 'Iris Model', 'qualified_name': 'iris_model', 'description': 'A model to predict the species of a flower based on its measurements.', 'version': '1.0.0'}]\n</code></pre> <pre><code>decorator = SimpleDecorator()\n\nmodel_manager.add_decorator(\"iris_model\", decorator)\n</code></pre> <p>When we access the model instance, we can see that it is now decorated:</p> <pre><code>model = model_manager.get_model(\"iris_model\")\n\nmodel\n</code></pre> <pre><code>SimpleDecorator(IrisModelMock)\n</code></pre>"}]}